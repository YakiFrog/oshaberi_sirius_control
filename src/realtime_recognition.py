#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆéŒ²éŸ³ãƒãƒƒãƒ•ã‚¡æ–¹å¼ï¼‰
PySide6 UIçµ±åˆç”¨ã«æœ€é©åŒ–
faster_whisper_test.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯
"""

import pyaudio
import numpy as np
import time
import threading
import queue
import tempfile
import wave
import os
from faster_whisper import WhisperModel

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
MODEL_CONFIG = {
    "model_size": "small",
    "device": "cpu",
    "compute_type": "int8",
    "cpu_threads": 6,
    "num_workers": 1
}

# èªè­˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
TRANSCRIBE_CONFIG = {
    "language": "ja",
    "beam_size": 1,
    "temperature": 0.0,
    "compression_ratio_threshold": 2.0,
    "log_prob_threshold": -0.8,
    "no_speech_threshold": 0.4,
    "condition_on_previous_text": False,
    "initial_prompt": "ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚",
    "word_timestamps": False,
    "vad_filter": True,
    "vad_parameters": {
        "min_silence_duration_ms": 800,
        "speech_pad_ms": 50,
        "threshold": 0.5
    }
}

# éŸ³å£°è¨­å®š
AUDIO_CONFIG = {
    "chunk": 1024,
    "format": pyaudio.paInt16,
    "channels": 1,
    "rate": 16000
}

class RealtimeRecognizer:
    def __init__(self, transcription_callback=None, silence_callback=None):
        self.model = None
        self.audio = None
        self.stream = None
        self.frames = []
        self.is_recording = False
        self.transcription_callback = transcription_callback
        self.silence_callback = silence_callback

        # æ²ˆé»™æ¤œå‡ºè¨­å®š
        self.last_voice_time = 0
        self.silence_threshold = 2.0  # 2ç§’
        self.voice_threshold = 100

    def _init_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’é…å»¶åˆæœŸåŒ–ï¼ˆé‡è¤‡å›é¿ï¼‰"""
        if self.model is None:
            print("ğŸš€ Faster Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
            try:
                self.model = WhisperModel(
                    MODEL_CONFIG["model_size"],
                    device=MODEL_CONFIG["device"],
                    compute_type=MODEL_CONFIG["compute_type"],
                    cpu_threads=MODEL_CONFIG["cpu_threads"],
                    num_workers=MODEL_CONFIG["num_workers"]
                )
                print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except Exception as e:
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                self.model = None
                raise

    def start_recognition(self):
        """éŸ³å£°èªè­˜ã‚’é–‹å§‹ï¼ˆéŒ²éŸ³é–‹å§‹ï¼‰"""
        if self.is_recording:
            return

        self._init_model()

        print("ğŸ¤ éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆéŒ²éŸ³ä¸­ï¼‰...")

        self.audio = pyaudio.PyAudio()
        self.frames = []
        self.stream = self.audio.open(
            format=AUDIO_CONFIG["format"],
            channels=AUDIO_CONFIG["channels"],
            rate=AUDIO_CONFIG["rate"],
            input=True,
            frames_per_buffer=AUDIO_CONFIG["chunk"]
        )

        self.is_recording = True
        self.last_voice_time = time.time()

        # éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        recording_thread = threading.Thread(target=self._recording_worker, daemon=True)
        recording_thread.start()

        # æ²ˆé»™ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        silence_thread = threading.Thread(target=self._silence_monitor, daemon=True)
        silence_thread.start()

    def stop_recognition(self):
        """éŸ³å£°èªè­˜ã‚’åœæ­¢ï¼ˆéŒ²éŸ³çµ‚äº†ã—ã¦èªè­˜å®Ÿè¡Œï¼‰"""
        if not self.is_recording:
            return

        self.is_recording = False

        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None

        if self.audio:
            self.audio.terminate()
            self.audio = None

        print("âœ… éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚éŸ³å£°èªè­˜ä¸­...")

        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦èªè­˜
        self._process_recording()

    def _recording_worker(self):
        """éŒ²éŸ³ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        while self.is_recording and self.stream:
            try:
                data = self.stream.read(AUDIO_CONFIG["chunk"], exception_on_overflow=False)
                self.frames.append(data)

                # éŸ³é‡ãƒã‚§ãƒƒã‚¯
                audio_data = np.frombuffer(data, dtype=np.int16)
                if len(audio_data) > 0:
                    volume = np.sqrt(np.mean(audio_data.astype(np.float64)**2))
                    if volume > self.voice_threshold:
                        self.last_voice_time = time.time()

            except Exception as e:
                if self.is_recording:
                    print(f"âŒ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
                break

    def _silence_monitor(self):
        """æ²ˆé»™ç›£è¦–ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        while self.is_recording:
            current_time = time.time()
            silence_duration = current_time - self.last_voice_time

            if silence_duration >= self.silence_threshold:
                print(f"ğŸ”‡ {silence_duration:.1f}ç§’ã®æ²ˆé»™ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸ")
                if self.silence_callback:
                    self.silence_callback()
                break

            time.sleep(0.1)

    def _process_recording(self):
        """éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦èªè­˜"""
        if not self.frames:
            print("âŒ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            temp_filename = temp_file.name
            wf = wave.open(temp_filename, 'wb')
            wf.setnchannels(AUDIO_CONFIG["channels"])
            wf.setsampwidth(self.audio.get_sample_size(AUDIO_CONFIG["format"]) if self.audio else 2)
            wf.setframerate(AUDIO_CONFIG["rate"])
            wf.writeframes(b''.join(self.frames))
            wf.close()

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            file_size = os.path.getsize(temp_filename)
            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes")

            if file_size < 1000:
                print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã¾ã™")
                return

            # éŸ³å£°èªè­˜
            print("ğŸ”„ éŸ³å£°èªè­˜å‡¦ç†é–‹å§‹...")
            segments, info = self.model.transcribe(
                temp_filename,
                language=TRANSCRIBE_CONFIG["language"],
                beam_size=TRANSCRIBE_CONFIG["beam_size"],
                temperature=TRANSCRIBE_CONFIG["temperature"],
                compression_ratio_threshold=TRANSCRIBE_CONFIG["compression_ratio_threshold"],
                log_prob_threshold=TRANSCRIBE_CONFIG["log_prob_threshold"],
                no_speech_threshold=TRANSCRIBE_CONFIG["no_speech_threshold"],
                condition_on_previous_text=TRANSCRIBE_CONFIG["condition_on_previous_text"],
                initial_prompt=TRANSCRIBE_CONFIG["initial_prompt"],
                word_timestamps=TRANSCRIBE_CONFIG["word_timestamps"],
                vad_filter=TRANSCRIBE_CONFIG["vad_filter"],
                vad_parameters=TRANSCRIBE_CONFIG["vad_parameters"]
            )
            print("âœ… éŸ³å£°èªè­˜å‡¦ç†å®Œäº†")

            # çµæœå‡¦ç†
            segments_list = list(segments)
            print(f"ğŸ” èªè­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments_list)}")
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«çµåˆï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
            text_parts = []
            for i, segment in enumerate(segments_list):
                segment_text = segment.text
                print(f"ğŸ” ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{i}: ã‚¿ã‚¤ãƒ—={type(segment_text)}, å†…å®¹={repr(segment_text)}")
                
                if isinstance(segment_text, bytes):
                    # ãƒã‚¤ãƒˆæ–‡å­—åˆ—ã®å ´åˆã€UTF-8ã§ãƒ‡ã‚³ãƒ¼ãƒ‰
                    try:
                        segment_text = segment_text.decode('utf-8', errors='ignore')
                        print(f"âœ… ãƒã‚¤ãƒˆã‹ã‚‰ãƒ‡ã‚³ãƒ¼ãƒ‰: {segment_text}")
                    except Exception as decode_error:
                        print(f"âŒ ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {decode_error}")
                        segment_text = str(segment_text, 'utf-8', errors='ignore')
                elif isinstance(segment_text, str):
                    # æ–‡å­—åˆ—ã®å ´åˆã€ãã®ã¾ã¾ä½¿ç”¨
                    print(f"âœ… æ–‡å­—åˆ—ã¨ã—ã¦å‡¦ç†: {segment_text}")
                else:
                    # ãã®ä»–ã®å ´åˆã€æ–‡å­—åˆ—ã«å¤‰æ›
                    print(f"âš ï¸ ãã®ä»–ã®å‹ã‹ã‚‰å¤‰æ›: {type(segment_text)}")
                    segment_text = str(segment_text)
                
                text_parts.append(segment_text)
            
            text = "".join(text_parts).strip()
            print(f"ğŸ¯ çµåˆå¾Œãƒ†ã‚­ã‚¹ãƒˆ: {repr(text)}")

            if text:
                confidence = self._calculate_confidence(segments_list, info)
                print(f"ğŸ¯ èªè­˜çµæœ: ã€Œ{text}ã€ (ç¢ºä¿¡åº¦: {confidence:.1f}%)")

                if self.transcription_callback:
                    self.transcription_callback(text, confidence)
            else:
                print("ğŸ¯ èªè­˜çµæœ: ï¼ˆç„¡éŸ³ã¾ãŸã¯èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰")

        except Exception as e:
            print(f"âŒ èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(temp_filename)
            except:
                pass

    def _calculate_confidence(self, segments, info):
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        try:
            word_confidences = []

            for segment in segments:
                if hasattr(segment, 'words') and segment.words:
                    for word in segment.words:
                        if hasattr(word, 'probability') and word.probability is not None:
                            confidence = min(100.0, max(0.0, (word.probability + 5.0) / 5.0 * 100))
                            word_confidences.append(confidence)

                if hasattr(segment, 'avg_logprob') and segment.avg_logprob is not None:
                    segment_confidence = min(100.0, max(0.0, (segment.avg_logprob + 5.0) / 5.0 * 100))
                    word_confidences.append(segment_confidence)

            if word_confidences:
                return sum(word_confidences) / len(word_confidences)
            else:
                return info.language_probability * 100 if hasattr(info, 'language_probability') else 50.0

        except:
            return 50.0

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # éŒ²éŸ³åœæ­¢
            if self.is_recording:
                self.stop_recognition()
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.stream:
                try:
                    self.stream.stop_stream()
                    self.stream.close()
                except:
                    pass
                self.stream = None

            # PyAudioã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.audio:
                try:
                    self.audio.terminate()
                except:
                    pass
                self.audio = None

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
            self.frames.clear()
            
            print("âœ… RealtimeRecognizer ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ RealtimeRecognizer ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—è­¦å‘Š: {e}")

    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.cleanup()