#!/usr/bin/env python3
"""
ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
PySide6 UIçµ±åˆç”¨ã«æœ€é©åŒ–
"""

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒã‚§ãƒƒã‚¯
try:
    import pyaudio
except ImportError:
    print("âŒ pyaudioãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    exit(1)

try:
    import numpy as np
except ImportError:
    print("âŒ numpyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    exit(1)

try:
    from faster_whisper import WhisperModel
except ImportError:
    print("âŒ faster_whisperãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    exit(1)

import time
import threading
import queue
import os

# =============================================================================
# ğŸš€ é«˜é€ŸåŒ–è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
# =============================================================================

MODEL_CONFIG = {
    "model_size": "small",
    "device": "cpu",
    "compute_type": "int8",
    "cpu_threads": 6,
    "num_workers": 1
}

TRANSCRIBE_CONFIG = {
    "language": "ja",
    "beam_size": 1,  # é«˜é€ŸåŒ–ã®ãŸã‚1ã«å¤‰æ›´
    "temperature": 0.0,
    "compression_ratio_threshold": 2.4,
    "log_prob_threshold": -1.0,
    "no_speech_threshold": 0.3,
    "condition_on_previous_text": True,
    "initial_prompt": "ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã€Œã‚·ãƒªã‚¦ã‚¹ãã‚“ã€ã‚’èã„ã¦ãã ã•ã„ã€‚",
    "word_timestamps": False,
    "vad_filter": True,
    "vad_parameters": {
        "min_silence_duration_ms": 300,
        "speech_pad_ms": 50,
        "threshold": 0.4
    }
}

REALTIME_CONFIG = {
    "chunk": 1024,
    "format": pyaudio.paInt16,
    "channels": 1,
    "rate": 16000,
    "buffer_seconds": 1.5,
    "overlap_seconds": 0.3,
    "processing_interval": 0.3
}

WAKE_WORD_CONFIG = {
    "wake_word": "ã‚·ãƒªã‚¦ã‚¹ãã‚“",
    "confidence_threshold": 60.0,
    "cooldown_seconds": 2.0,
    "max_detection_history": 10,
    "debug_mode": False
}

# =============================================================================
# ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚¯ãƒ©ã‚¹
# =============================================================================

class WakeWordDetector:
    def __init__(self, wake_word_callback=None):
        self.model = None  # é…å»¶åˆæœŸåŒ–
        self.audio = None
        self.stream = None
        self.is_running = False
        self.last_processed_time = 0
        self.audio_buffer = np.array([], dtype=np.int16)
        self.buffer_lock = threading.Lock()
        self.wake_word = WAKE_WORD_CONFIG["wake_word"]
        self.confidence_threshold = WAKE_WORD_CONFIG["confidence_threshold"]
        self.cooldown_seconds = WAKE_WORD_CONFIG["cooldown_seconds"]
        self.last_detection_time = 0
        self.detection_history = []
        self.debug_mode = WAKE_WORD_CONFIG.get("debug_mode", False)
        self.wake_word_callback = wake_word_callback or self._default_wake_word_callback

    def _init_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’é…å»¶åˆæœŸåŒ–"""
        if self.model is None:
            print("ğŸš€ Faster Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
            self.model = WhisperModel(
                MODEL_CONFIG["model_size"],
                device=MODEL_CONFIG["device"],
                compute_type=MODEL_CONFIG["compute_type"],
                cpu_threads=MODEL_CONFIG["cpu_threads"],
                num_workers=MODEL_CONFIG["num_workers"]
            )
            print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    def _default_wake_word_callback(self, detected_text, confidence):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        print(f"\nğŸ¯ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: ã€Œ{detected_text}ã€ (ç¢ºä¿¡åº¦: {confidence:.1f}%)")
        print("ğŸ”” ã‚·ãƒªã‚¦ã‚¹ãã‚“ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸï¼")

    def start_detection(self):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’é–‹å§‹"""
        if self.is_running:
            return

        self._init_model()

        print(f"ğŸ¤ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’é–‹å§‹ã—ã¾ã™...")
        print(f"ğŸ’¡ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰: ã€Œ{self.wake_word}ã€")

        self.audio = pyaudio.PyAudio()
        self.stream = self.audio.open(
            format=REALTIME_CONFIG["format"],
            channels=REALTIME_CONFIG["channels"],
            rate=REALTIME_CONFIG["rate"],
            input=True,
            frames_per_buffer=REALTIME_CONFIG["chunk"]
        )

        self.is_running = True

        # éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        recording_thread = threading.Thread(target=self._recording_worker, daemon=True)
        recording_thread.start()

        # æ¤œå‡ºã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        detection_thread = threading.Thread(target=self._detection_worker, daemon=True)
        detection_thread.start()

    def stop_detection(self):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’åœæ­¢"""
        if not self.is_running:
            return

        self.is_running = False

        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None

        if self.audio:
            self.audio.terminate()
            self.audio = None

        print("âœ… ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’çµ‚äº†ã—ã¾ã—ãŸ")

    def _recording_worker(self):
        """éŸ³å£°éŒ²éŸ³ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        while self.is_running and self.stream:
            try:
                data = self.stream.read(REALTIME_CONFIG["chunk"], exception_on_overflow=False)
                audio_chunk = np.frombuffer(data, dtype=np.int16)

                with self.buffer_lock:
                    self.audio_buffer = np.concatenate([self.audio_buffer, audio_chunk])

            except Exception as e:
                if self.is_running:
                    print(f"âŒ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
                break

    def _detection_worker(self):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¯ãƒ¼ã‚«ãƒ¼"""
        while self.is_running:
            current_time = time.time()

            if current_time - self.last_processed_time < REALTIME_CONFIG["processing_interval"]:
                time.sleep(0.05)
                continue

            if current_time - self.last_detection_time < self.cooldown_seconds:
                time.sleep(0.05)
                continue

            with self.buffer_lock:
                buffer_duration = len(self.audio_buffer) / REALTIME_CONFIG["rate"]

                if buffer_duration < REALTIME_CONFIG["buffer_seconds"]:
                    time.sleep(0.05)
                    continue

                process_samples = int(REALTIME_CONFIG["buffer_seconds"] * REALTIME_CONFIG["rate"])
                overlap_samples = int(REALTIME_CONFIG["overlap_seconds"] * REALTIME_CONFIG["rate"])

                audio_to_process = self.audio_buffer[-process_samples:]

                keep_samples = overlap_samples
                if len(self.audio_buffer) > keep_samples:
                    self.audio_buffer = self.audio_buffer[-keep_samples:]

            try:
                self._process_audio_for_wake_word(audio_to_process)
                self.last_processed_time = current_time

            except Exception as e:
                if self.is_running:
                    print(f"âŒ æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")

    def _process_audio_for_wake_word(self, audio_chunk):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º"""
        audio_np = audio_chunk.astype(np.float32) / 32768.0

        volume = self._calculate_volume(audio_chunk)
        if volume < 100:
            return

        segments, info = self.model.transcribe(
            audio_np,
            language=TRANSCRIBE_CONFIG["language"],
            beam_size=TRANSCRIBE_CONFIG["beam_size"],
            temperature=TRANSCRIBE_CONFIG["temperature"],
            compression_ratio_threshold=TRANSCRIBE_CONFIG["compression_ratio_threshold"],
            log_prob_threshold=TRANSCRIBE_CONFIG["log_prob_threshold"],
            no_speech_threshold=TRANSCRIBE_CONFIG["no_speech_threshold"],
            condition_on_previous_text=TRANSCRIBE_CONFIG["condition_on_previous_text"],
            initial_prompt=TRANSCRIBE_CONFIG["initial_prompt"],
            word_timestamps=TRANSCRIBE_CONFIG["word_timestamps"],
            vad_filter=TRANSCRIBE_CONFIG["vad_filter"],
            vad_parameters=TRANSCRIBE_CONFIG["vad_parameters"]
        )

        segments_list = list(segments)
        if not segments_list:
            return

        text = "".join(segment.text for segment in segments_list).strip()
        if not text:
            return

        confidence = self._calculate_simple_confidence(segments_list, info)

        if self._check_wake_word(text, confidence):
            detection_info = {
                'timestamp': time.time(),
                'text': text,
                'confidence': confidence,
                'duration': len(audio_chunk) / REALTIME_CONFIG["rate"]
            }
            self.detection_history.append(detection_info)

            if len(self.detection_history) > WAKE_WORD_CONFIG["max_detection_history"]:
                self.detection_history.pop(0)

            self.wake_word_callback(text, confidence)
            self.last_detection_time = time.time()

    def _check_wake_word(self, text, confidence):
        """ãƒ†ã‚­ã‚¹ãƒˆã«ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self.debug_mode and confidence < self.confidence_threshold:
            return False

        if len(text.strip()) < 1:
            return False

        if not any(ord(char) > 127 for char in text):
            return False

        text_lower = text.lower()

        if self.wake_word in text:
            return True

        wake_word_variants = [
            "ã‚·ãƒªã‚¦ã‚¹ãã‚“", "ã‚·ãƒªã‚¦ã‚¹", "ã—ã‚Šã†ã™ãã‚“", "ã—ã‚Šã†ã™",
            "ã‚·ãƒªã‚¦ã‚¹ ãã‚“", "ã—ã‚Šã†ã™ ãã‚“", "ã‚·ãƒªã‚¦ã‚¹ã•ã‚“", "ã—ã‚Šã†ã™ã•ã‚“",
            "ã­ãˆï¼Œã‚·ãƒªã‚¦ã‚¹ãã‚“", "ã­ãˆã‚·ãƒªã‚¦ã‚¹ãã‚“", "ã­ãˆã€ã‚·ãƒªã‚¦ã‚¹ãã‚“", "ã­ãˆ ã‚·ãƒªã‚¦ã‚¹ãã‚“",
            "ãŠã„ã€ã‚·ãƒªã‚¦ã‚¹ãã‚“", "ãŠã„ã‚·ãƒªã‚¦ã‚¹ãã‚“", "ã¡ã‚‡ã£ã¨ã€ã‚·ãƒªã‚¦ã‚¹ãã‚“", "ã¡ã‚‡ã£ã¨ã‚·ãƒªã‚¦ã‚¹ãã‚“"
        ]

        for variant in wake_word_variants:
            if variant in text_lower:
                return True

        if "ã‚·ãƒªã‚¦ã‚¹" in text or "ã—ã‚Šã†ã™" in text:
            return True

        return False

    def _calculate_volume(self, audio_chunk):
        """éŸ³é‡ã‚’è¨ˆç®—"""
        if len(audio_chunk) == 0:
            return 0
        return np.sqrt(np.mean(audio_chunk.astype(np.float64)**2))

    def _calculate_simple_confidence(self, segments, info):
        """ç°¡æ˜“çš„ãªä¿¡é ¼åº¦è¨ˆç®—"""
        try:
            if hasattr(info, 'language_probability') and info.language_probability:
                return info.language_probability * 100

            confidences = []
            for segment in segments:
                if hasattr(segment, 'avg_logprob') and segment.avg_logprob is not None:
                    confidence = min(100.0, max(0.0, (segment.avg_logprob + 5.0) / 5.0 * 100))
                    confidences.append(confidence)

            return sum(confidences) / len(confidences) if confidences else 50.0

        except:
            return 50.0

    def get_detection_history(self):
        """æ¤œå‡ºå±¥æ­´ã‚’å–å¾—"""
        return self.detection_history.copy()

    def clear_detection_history(self):
        """æ¤œå‡ºå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
        self.detection_history.clear()