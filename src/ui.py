from PySide6.QtUiTools import QUiLoader
from PySide6.QtCore import QFile, QObject, Signal
from PySide6.QtWidgets import QTextEdit, QPushButton, QLineEdit, QComboBox, QLabel
from wake_word import WakeWordDetector
from voice_synthesis import VoiceSynthesizer
from realtime_recognition import RealtimeRecognizer
import time
import threading
import requests
import json

class WakeWordController(QObject):
    """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªUIæ›´æ–°ç”¨ï¼‰"""
    wake_word_detected = Signal(str, float)  # æ¤œå‡ºãƒ†ã‚­ã‚¹ãƒˆã¨ç¢ºä¿¡åº¦
    model_loaded = Signal()  # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ã‚·ã‚°ãƒŠãƒ«

    def __init__(self):
        super().__init__()
        self.detector = None  # é…å»¶åˆæœŸåŒ–
        self.is_detecting = False
        self.model_loading = False

    def preload_model(self):
        """ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰"""
        if self.model_loading or self.detector is not None:
            return

        self.model_loading = True
        print("ğŸš€ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰ä¸­...")

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        import threading
        load_thread = threading.Thread(target=self._preload_model_worker, daemon=True)
        load_thread.start()

    def _preload_model_worker(self):
        """ãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒ­ãƒ¼ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            from wake_word import WakeWordDetector
            self.detector = WakeWordDetector(self._on_wake_word_detected)
            # ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
            self.detector._init_model()
            self.model_loaded.emit()
            print("âœ… ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.model_loading = False

    def _get_detector(self):
        """æ¤œå‡ºå™¨ã‚’å–å¾—ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆã®ã¿ï¼‰"""
        if self.detector is None:
            if self.model_loading:
                print("â³ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
                return None
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãã®å ´ã§ãƒ­ãƒ¼ãƒ‰
                from wake_word import WakeWordDetector
                self.detector = WakeWordDetector(self._on_wake_word_detected)
        return self.detector

    def _on_wake_word_detected(self, text, confidence):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.wake_word_detected.emit(text, confidence)

    def toggle_detection(self):
        """æ¤œå‡ºã®é–‹å§‹/åœæ­¢ã‚’åˆ‡ã‚Šæ›¿ãˆ"""
        detector = self._get_detector()
        if detector is None:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒã¾ã ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        if self.is_detecting:
            detector.stop_detection()
            self.is_detecting = False
        else:
            detector.start_detection()
            self.is_detecting = True
        return self.is_detecting

class VoiceController(QObject):
    """éŸ³å£°å…¥å‡ºåŠ›ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼"""
    transcription_received = Signal(str, float)  # èªè­˜ãƒ†ã‚­ã‚¹ãƒˆã¨ç¢ºä¿¡åº¦
    silence_detected = Signal()  # æ²ˆé»™æ¤œå‡º
    model_loaded = Signal()  # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ã‚·ã‚°ãƒŠãƒ«
    speech_completed = Signal()  # éŸ³å£°åˆæˆå®Œäº†ã‚·ã‚°ãƒŠãƒ«
    speech_started = Signal()  # éŸ³å£°å†ç”Ÿé–‹å§‹ã‚·ã‚°ãƒŠãƒ«
    llm_response_received = Signal(str)  # LLMå¿œç­”å—ä¿¡ã‚·ã‚°ãƒŠãƒ«

    # åˆ©ç”¨å¯èƒ½ãªLLMãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
    AVAILABLE_MODELS = {
        "mistralai/magistral-small-2509": "Mistral Smallãƒ¢ãƒ‡ãƒ«",
        "openai/gpt-oss-20b": "OpenAI GPT OSS 20Bãƒ¢ãƒ‡ãƒ«"
    }

    def __init__(self):
        super().__init__()
        self.synthesizer = VoiceSynthesizer()
        self.recognizer = None  # é…å»¶åˆæœŸåŒ–
        self.is_recognizing = False
        
        # éŸ³å£°å†ç”Ÿã‚³ãƒãƒ³ãƒ‰ã‚’æ¤œå‡º
        self.audio_command = self._detect_audio_command()
        print(f"ğŸ”Š UIéŸ³å£°å†ç”Ÿã‚³ãƒãƒ³ãƒ‰: {self.audio_command}")
        
        self.is_speaking = False  # éŸ³å£°åˆæˆä¸­ãƒ•ãƒ©ã‚°
        self.model_loading = False
        self.llm_model = "mistralai/magistral-small-2509"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
        
        # éŸ³å£°å†ç”Ÿé–¢é€£
        self.audio_process = None  # éŸ³å£°å†ç”Ÿãƒ—ãƒ­ã‚»ã‚¹
        self.speech_thread = None  # éŸ³å£°åˆæˆã‚¹ãƒ¬ãƒƒãƒ‰
        self.lipsync_thread = None  # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚¹ãƒ¬ãƒƒãƒ‰

    def _detect_audio_command(self):
        """åˆ©ç”¨å¯èƒ½ãªéŸ³å£°å†ç”Ÿã‚³ãƒãƒ³ãƒ‰ã‚’æ¤œå‡º"""
        import shutil
        
        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ã®ã‚³ãƒãƒ³ãƒ‰å„ªå…ˆé †ä½
        commands = [
            'paplay',  # PulseAudio (Ubuntu/Linux preferred)
            'aplay',   # ALSA (Linux fallback)
            'ffplay',  # ffmpeg (Linux/cross-platform)
            'afplay',  # macOS
        ]
        
        for cmd in commands:
            if shutil.which(cmd):
                return cmd
        
        return None

    def preload_model(self):
        """éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰"""
        if self.model_loading or self.recognizer is not None:
            return

        self.model_loading = True
        print("ğŸš€ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰ä¸­...")

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        import threading
        load_thread = threading.Thread(target=self._preload_model_worker, daemon=True)
        load_thread.start()

    def _preload_model_worker(self):
        """ãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒ­ãƒ¼ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            from realtime_recognition import RealtimeRecognizer
            self.recognizer = RealtimeRecognizer(
                transcription_callback=self._on_transcription,
                silence_callback=self._on_silence
            )
            # tqdmã®ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚’é…ã‚‰ã›ã‚‹
            print("âœ… éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æº–å‚™å®Œäº†")
            self.model_loaded.emit()
        except Exception as e:
            print(f"âŒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.model_loading = False

    def _get_recognizer(self):
        """èªè­˜å™¨ã‚’å–å¾—ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆã®ã¿ï¼‰"""
        if self.recognizer is None:
            if self.model_loading:
                print("â³ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
                return None
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãã®å ´ã§ãƒ­ãƒ¼ãƒ‰
                from realtime_recognition import RealtimeRecognizer
                self.recognizer = RealtimeRecognizer(
                    transcription_callback=self._on_transcription,
                    silence_callback=self._on_silence
                )
        return self.recognizer

    def _on_transcription(self, text, confidence):
        """éŸ³å£°èªè­˜çµæœã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.transcription_received.emit(text, confidence)

    def _on_silence(self):
        """æ²ˆé»™æ¤œå‡ºã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.silence_detected.emit()

    def chat_with_llm(self, user_message: str):
        """LLMã¨ãƒãƒ£ãƒƒãƒˆã—ã¦å¿œç­”ã‚’å–å¾—"""
        def _chat_async():
            try:
                url = "http://localhost:1234/v1/chat/completions"
                payload = {
                    "model": self.llm_model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
                        },
                        {
                            "role": "user", 
                            "content": user_message
                        } 
                    ],
                    "temperature": 0.7,
                    "max_tokens": -1,
                    "stream": False
                }

                response = requests.post(url, json=payload, timeout=30)
                response.raise_for_status()
                result = response.json()
                ai_message = result["choices"][0]["message"]["content"]
                self.llm_response_received.emit(ai_message)
            except Exception as e:
                error_msg = f"LLMã‚¨ãƒ©ãƒ¼: {e}"
                self.llm_response_received.emit(error_msg)

        thread = threading.Thread(target=_chat_async, daemon=True)
        thread.start()

    def cancel_speech(self):
        """éŸ³å£°å†ç”Ÿã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        if not self.is_speaking:
            return False
            
        try:
            # éŸ³å£°å†ç”Ÿãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢
            if self.audio_process and self.audio_process.poll() is None:
                self.audio_process.terminate()
                self.audio_process.wait(timeout=1.0)
                print("ğŸ›‘ éŸ³å£°å†ç”Ÿã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’åœæ­¢ï¼ˆã‚·ã‚°ãƒŠãƒ«ã§é€šçŸ¥ï¼‰
            self._set_mouth_pattern_async(None)
            
            # ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            self.is_speaking = False
            self.audio_process = None
            self.speech_thread = None
            self.lipsync_thread = None
            
            self.speech_completed.emit()
            return True
            
        except Exception as e:
            print(f"âš ï¸ éŸ³å£°ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def speak_response(self, text: str):
        """å¿œç­”éŸ³å£°ã‚’éåŒæœŸã§å†ç”Ÿ"""
        if self.is_speaking:
            return  # æ—¢ã«ç™ºè©±ä¸­ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            
        self.is_speaking = True
        
        def _speak_async():
            try:
                self._speak_with_lipsync(text)
            finally:
                self.is_speaking = False
                self.audio_process = None
                self.speech_thread = None
                self.lipsync_thread = None
                self.speech_completed.emit()
        
        self.speech_thread = threading.Thread(target=_speak_async, daemon=True)
        self.speech_thread.start()

    def _speak_with_lipsync(self, text: str):
        """éŸ³å£°åˆæˆ + ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«å¯¾å¿œç‰ˆï¼‰"""
        if not self.synthesizer.synthesizer:
            print("âŒ SynthesizerãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return

        try:
            print(f"ğŸ¤ åˆæˆ: ã€Œ{text}ã€ (é€Ÿåº¦: {self.synthesizer.speed_scale}x, ã‚¹ã‚¿ã‚¤ãƒ«: {self.synthesizer.style_id})")

            # AudioQueryä½œæˆ
            audio_query = self.synthesizer.synthesizer.create_audio_query(text, self.synthesizer.style_id)
            self.synthesizer._set_speed_scale(audio_query, self.synthesizer.speed_scale)

            # éŸ³å£°åˆæˆ
            wav_data = self.synthesizer.synthesizer.synthesis(audio_query, self.synthesizer.style_id)
            print("âœ… éŸ³å£°åˆæˆæˆåŠŸ")

            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Ÿè¡Œï¼ˆãƒ—ãƒ­ã‚»ã‚¹ã‚’è¿”ã™ï¼‰
            self.audio_process = self._perform_lipsync_with_cancel(audio_query, wav_data, self.synthesizer.speed_scale)

        except Exception as e:
            print(f"âŒ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")

    def _perform_lipsync_with_cancel(self, audio_query, wav_data, speed_scale: float):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«å¯¾å¿œç‰ˆï¼‰"""
        # å£å½¢çŠ¶ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ
        mouth_sequence = self.synthesizer._get_mouth_shape_sequence(audio_query, speed_scale)

        print("ğŸ“ å£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹:")
        for i, (seq_time, mouth_shape, duration) in enumerate(mouth_sequence[:10]):
            print(".2f")
        if len(mouth_sequence) > 10:
            print(f"  ... ä»–{len(mouth_sequence) - 10}å€‹")

        # åŒæœŸã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ
        audio_start_event = threading.Event()

        # éŸ³å£°å†ç”Ÿã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        audio_thread = threading.Thread(
            target=self._play_audio_with_process,
            args=(wav_data, audio_start_event),
            daemon=True
        )
        audio_thread.start()

        # éŸ³å£°å†ç”Ÿé–‹å§‹ã‚’å¾…æ©Ÿ
        audio_start_event.wait()
        actual_audio_start = time.time()

        print(".6f")

        # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Ÿè¡Œ
        timing_stats = {'perfect': 0, 'good': 0, 'poor': 0}
        first_mouth_pattern = True

        for seq_time, mouth_shape, duration in mouth_sequence:
            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒã‚§ãƒƒã‚¯
            if not self.is_speaking:
                break
                
            # ç›®æ¨™æ™‚é–“ = éŸ³å£°é–‹å§‹æ™‚é–“ + ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ™‚é–“
            target_time = actual_audio_start + seq_time

            # é«˜ç²¾åº¦ã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¶å¾¡
            while self.is_speaking:  # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒã‚§ãƒƒã‚¯
                current_time = time.time()
                time_to_target = target_time - current_time

                if time_to_target <= 0.0001:
                    break
                elif time_to_target > 0:
                    if time_to_target < 0.001:
                        pass
                    else:
                        time.sleep(max(0.0001, time_to_target - 0.0005))
                else:
                    break

            if not self.is_speaking:
                break

            # å£ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š
            server_pattern = f"mouth_{mouth_shape}" if mouth_shape else None
            if server_pattern:
                if first_mouth_pattern:
                    success = self.synthesizer._set_mouth_pattern(server_pattern)
                    if not success:
                        print(f"âš ï¸ å£ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šå¤±æ•—: {server_pattern}")
                    first_mouth_pattern = False
                else:
                    self.synthesizer._set_mouth_pattern_async(server_pattern)

                # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç²¾åº¦è©•ä¾¡
                actual_time = time.time()
                timing_error_ms = (actual_time - target_time) * 1000

                if abs(timing_error_ms) <= 5:
                    sync_indicator = "âœ“"
                    timing_stats['perfect'] += 1
                elif abs(timing_error_ms) <= 15:
                    sync_indicator = "~"
                    timing_stats['good'] += 1
                else:
                    sync_indicator = "âš "
                    timing_stats['poor'] += 1

                print(".1f")

        # çµ±è¨ˆè¡¨ç¤º
        total_patterns = timing_stats['perfect'] + timing_stats['good'] + timing_stats['poor']
        if total_patterns > 0:
            perfect_rate = timing_stats['perfect'] / total_patterns * 100
            print(".1f")

        # çµ‚äº†æ™‚ã«å£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
        if self.is_speaking:  # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿
            time.sleep(0.2)
            self.synthesizer._set_mouth_pattern_async(None)
            print("âœ… ç™ºè©±å®Œäº†\n")

        return self.audio_process

    def _play_audio_with_process(self, wav_data, start_event):
        """éŸ³å£°ã‚’å†ç”Ÿã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä¿å­˜ï¼ˆã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œï¼‰"""
        if not self.audio_command:
            print("âŒ éŸ³å£°å†ç”Ÿã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            if start_event:
                start_event.set()
            return
        
        try:
            import tempfile
            import subprocess
            import os
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_file.write(wav_data)
                temp_file_path = temp_file.name

            # å†ç”Ÿé–‹å§‹ã‚’é€šçŸ¥
            start_event.set()

            # éŸ³å£°å†ç”Ÿé–‹å§‹ã‚’é€šçŸ¥
            self.speech_started.emit()

            # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ã®éŸ³å£°å†ç”Ÿ
            if self.audio_command == 'ffplay':
                # ffplayï¼ˆãƒ­ã‚°å‡ºåŠ›ã‚’æŠ‘åˆ¶ï¼‰
                self.audio_process = subprocess.Popen([
                    'ffplay', '-nodisp', '-autoexit', '-loglevel', 'quiet', temp_file_path
                ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            else:
                # aplay, paplay, afplay
                self.audio_process = subprocess.Popen([self.audio_command, temp_file_path],
                                                    stdout=subprocess.DEVNULL,
                                                    stderr=subprocess.DEVNULL)
            
            self.audio_process.wait()
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
        except Exception as e:
            print(f"âŒ éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")

    def start_recognition(self):
        """éŸ³å£°èªè­˜ã‚’é–‹å§‹"""
        recognizer = self._get_recognizer()
        if recognizer is None:
            print("âŒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãŒã¾ã ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
            
        if self.is_speaking:
            print("â³ éŸ³å£°åˆæˆä¸­ã§ã™ã€‚åˆæˆå®Œäº†ã¾ã§å¾…æ©Ÿã—ã¾ã™...")
            # åˆæˆå®Œäº†ã‚’å¾…ã£ã¦ã‹ã‚‰èªè­˜ã‚’é–‹å§‹
            def _delayed_start():
                while self.is_speaking:
                    time.sleep(0.1)
                if not self.is_recognizing:
                    recognizer.start_recognition()
                    self.is_recognizing = True
            
            thread = threading.Thread(target=_delayed_start, daemon=True)
            thread.start()
            return
            
        if not self.is_recognizing:
            recognizer.start_recognition()
            self.is_recognizing = True

    def stop_recognition(self):
        """éŸ³å£°èªè­˜ã‚’åœæ­¢"""
        if self.is_recognizing and self.recognizer:
            self.recognizer.stop_recognition()
            self.is_recognizing = False

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # éŸ³å£°åˆæˆã‚­ãƒ£ãƒ³ã‚»ãƒ«
            self.cancel_speech()
            
            # éŸ³å£°èªè­˜åœæ­¢ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.stop_recognition()
            if hasattr(self.recognizer, 'cleanup') and self.recognizer:
                self.recognizer.cleanup()
            
            # VOICEVOXã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.synthesizer:
                self.synthesizer.cleanup()
            
            print("âœ… VoiceController ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ VoiceControllerã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—è­¦å‘Š: {e}")

class MainWindow:
    def __init__(self):
        # .uiãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        ui_file = QFile("src/main_window.ui")
        ui_file.open(QFile.ReadOnly)
        loader = QUiLoader()
        self.window = loader.load(ui_file)
        ui_file.close()

        # ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã¸ã®å‚ç…§ã‚’å–å¾—
        self.chat_display = self.window.findChild(QTextEdit, "chatDisplay")
        self.send_button = self.window.findChild(QPushButton, "sendButton")
        self.manual_audio_button = self.window.findChild(QPushButton, "manualAudioButton")
        self.wake_word_button = self.window.findChild(QPushButton, "wakeWordButton")
        self.message_input = self.window.findChild(QLineEdit, "messageInput")
        self.model_selector = self.window.findChild(QComboBox, "modelSelector")
        self.cancel_speech_button = self.window.findChild(QPushButton, "cancelSpeechButton")

        # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–
        self.wake_controller = WakeWordController()
        self.wake_controller.wake_word_detected.connect(self._on_wake_word_detected)
        self.wake_controller.model_loaded.connect(self._on_model_loaded)

        # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰
        self.wake_controller.preload_model()

        # éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–
        self.voice_controller = VoiceController()
        self.voice_controller.transcription_received.connect(self._on_transcription_received)
        self.voice_controller.silence_detected.connect(self._on_silence_detected)
        self.voice_controller.model_loaded.connect(self._on_voice_model_loaded)
        self.voice_controller.speech_completed.connect(self._on_speech_completed)
        self.voice_controller.speech_started.connect(self._on_speech_started)
        self.voice_controller.llm_response_received.connect(self._on_llm_response_received)

        # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰
        self.voice_controller.preload_model()

        # ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š
        self.wake_word_button.clicked.connect(self._on_wake_word_button_clicked)
        self.manual_audio_button.clicked.connect(self._on_manual_audio_button_clicked)
        self.send_button.clicked.connect(self._on_send_button_clicked)
        self.message_input.returnPressed.connect(self._on_send_button_clicked)
        self.model_selector.currentTextChanged.connect(self._on_model_changed)
        self.cancel_speech_button.clicked.connect(self._on_cancel_speech_button_clicked)

        # ãƒ¢ãƒ‡ãƒ«ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        self._setup_model_selector()

        # ãƒœã‚¿ãƒ³ã®åˆæœŸã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        self._setup_button_styles()

        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã®åˆæœŸçŠ¶æ…‹ï¼ˆç„¡åŠ¹ï¼‰
        self.cancel_speech_button.setEnabled(False)

        # åˆæœŸçŠ¶æ…‹
        self._update_wake_word_button_text()
        self.current_transcription = ""  # éŸ³å£°èªè­˜ä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆ

    def _setup_button_styles(self):
        """å…¨ãƒœã‚¿ãƒ³ã®åˆæœŸã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š"""
        # é€ä¿¡ãƒœã‚¿ãƒ³ï¼ˆé’è‰²ï¼‰
        self.send_button.setStyleSheet("""
            QPushButton {
                background-color: #339af0;
                color: white;
                border: 2px solid #228be6;
                border-radius: 5px;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #228be6;
            }
            QPushButton:pressed {
                background-color: #1c7ed6;
            }
        """)

        # æ‰‹å‹•éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸è‰²ï¼‰
        self.manual_audio_button.setStyleSheet("""
            QPushButton {
                background-color: #ff922b;
                color: white;
                border: 2px solid #fd7e14;
                border-radius: 5px;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #fd7e14;
            }
            QPushButton:pressed {
                background-color: #f76707;
            }
        """)

        # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®åˆæœŸã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆåœæ­¢ä¸­ï¼‰
        self._update_wake_word_button_text()

        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ«
        self.cancel_speech_button.setStyleSheet("""
            QPushButton {
                background-color: #dc3545;
                color: white;
                border: 2px solid #c82333;
                border-radius: 5px;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #c82333;
            }
            QPushButton:pressed {
                background-color: #bd2130;
            }
            QPushButton:disabled {
                background-color: #6c757d;
                border-color: #545b62;
                color: #adb5bd;
            }
        """)

    def _setup_model_selector(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã®åˆæœŸåŒ–"""
        self.model_selector.clear()
        for model_name, description in self.voice_controller.AVAILABLE_MODELS.items():
            display_text = f"{description} ({model_name})"
            self.model_selector.addItem(display_text, model_name)
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        default_index = self.model_selector.findData(self.voice_controller.llm_model)
        if default_index >= 0:
            self.model_selector.setCurrentIndex(default_index)

    def _on_wake_word_button_clicked(self):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ"""
        is_detecting = self.wake_controller.toggle_detection()
        if is_detecting is False and self.wake_controller.model_loading:
            self._add_chat_message("â³ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
            return
            
        self._update_wake_word_button_text()
        
        if is_detecting:
            self._add_chat_message("ğŸ¤ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        else:
            self._add_chat_message("ğŸ›‘ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’åœæ­¢ã—ã¾ã—ãŸ")

    def _on_model_loaded(self):
        """ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†æ™‚ã®å‡¦ç†"""
        self._add_chat_message("âœ… ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¾ã—ãŸ")

    def _on_voice_model_loaded(self):
        """éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†æ™‚ã®å‡¦ç†"""
        self._add_chat_message("âœ… éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¾ã—ãŸ")

    def _on_llm_response_received(self, response: str):
        """LLMå¿œç­”å—ä¿¡æ™‚ã®å‡¦ç†"""
        # è€ƒãˆä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤ã—ã¦å¿œç­”ã‚’è¡¨ç¤º
        current_text = self.chat_display.toPlainText()
        lines = current_text.split('\n')
        if lines and "è€ƒãˆä¸­..." in lines[-1]:
            lines = lines[:-1]
            current_text = '\n'.join(lines)
            self.chat_display.setPlainText(current_text)
        
        self._add_chat_message(f"ğŸ¤– AI: {response}")
        
        # å¿œç­”ã‚’éŸ³å£°åˆæˆ + ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯
        self.voice_controller.speak_response(response)

    def _on_speech_started(self):
        """éŸ³å£°å†ç”Ÿé–‹å§‹æ™‚ã®å‡¦ç†"""
        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
        self.cancel_speech_button.setEnabled(True)

    def _on_speech_completed(self):
        
        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
        self.cancel_speech_button.setEnabled(True)

    def _on_speech_completed(self):
        """éŸ³å£°åˆæˆå®Œäº†æ™‚ã®å‡¦ç†"""
        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–
        self.cancel_speech_button.setEnabled(False)
        
        # éŸ³å£°åˆæˆå®Œäº†å¾Œã«éŸ³å£°èªè­˜ã‚’é–‹å§‹
        if not self.voice_controller.is_recognizing:
            self.voice_controller.start_recognition()
            self._add_chat_message("ğŸ¤ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")

    def _update_wake_word_button_text(self):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã¨è‰²ã‚’æ›´æ–°"""
        if self.wake_controller.is_detecting:
            self.wake_word_button.setText("ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥åœæ­¢")
            self.wake_word_button.setStyleSheet("""
                QPushButton {
                    background-color: #ff6b6b;
                    color: white;
                    border: 2px solid #ff5252;
                    border-radius: 5px;
                    padding: 5px;
                }
                QPushButton:hover {
                    background-color: #ff5252;
                }
                QPushButton:pressed {
                    background-color: #ff3838;
                }
            """)
        else:
            self.wake_word_button.setText("ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥é–‹å§‹")
            self.wake_word_button.setStyleSheet("""
                QPushButton {
                    background-color: #51cf66;
                    color: white;
                    border: 2px solid #40c057;
                    border-radius: 5px;
                    padding: 5px;
                }
                QPushButton:hover {
                    background-color: #40c057;
                }
                QPushButton:pressed {
                    background-color: #37b24d;
                }
            """)

    def _on_wake_word_detected(self, text, confidence):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºæ™‚ã®UIæ›´æ–°"""
        # å³åº§ã«æ¤œå‡ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        message = f"ğŸ¯ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: ã€Œ{text}ã€ (ç¢ºä¿¡åº¦: {confidence:.1f}%)"
        self._add_chat_message(message)

        # å¿œç­”éŸ³å£°ã‚’éåŒæœŸã§å†ç”Ÿï¼ˆåˆæˆå®Œäº†å¾Œã«éŸ³å£°èªè­˜ã‚’é–‹å§‹ï¼‰
        self.voice_controller.speak_response("ã¯ã„ï¼Œãªã‚“ã§ã™ã‹ï¼Ÿ")

    def _on_transcription_received(self, text, confidence):
        """éŸ³å£°èªè­˜çµæœå—ä¿¡æ™‚ã®å‡¦ç†"""
        message = f"ğŸ¯ èªè­˜: ã€Œ{text}ã€ (ç¢ºä¿¡åº¦: {confidence:.1f}%)"
        self._add_chat_message(message)
        self.current_transcription = text

    def _on_silence_detected(self):
        """æ²ˆé»™æ¤œå‡ºæ™‚ã®å‡¦ç†"""
        self._add_chat_message("ğŸ”‡ æ²ˆé»™ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚è‡ªå‹•é€ä¿¡ã—ã¾ã™...")
        self.voice_controller.stop_recognition()
        
        if self.current_transcription:
            # éŸ³å£°èªè­˜ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’LLMã«é€ä¿¡
            self._add_chat_message(f"ğŸ‘¤ ã‚ãªãŸ: {self.current_transcription}")
            self._add_chat_message("ğŸ¤– AI: è€ƒãˆä¸­...")
            self.voice_controller.chat_with_llm(self.current_transcription)
            self.current_transcription = ""  # ãƒªã‚»ãƒƒãƒˆ

    def _on_manual_audio_button_clicked(self):
        """æ‰‹å‹•éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if self.voice_controller.model_loading:
            self._add_chat_message("â³ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
            return
            
        if self.voice_controller.is_recognizing:
            self.voice_controller.stop_recognition()
            self._add_chat_message("ğŸ›‘ éŸ³å£°å…¥åŠ›ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        else:
            self.voice_controller.start_recognition()
            self._add_chat_message("ğŸ¤ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")

        self._update_manual_audio_button_text()

    def _update_manual_audio_button_text(self):
        """æ‰‹å‹•éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°"""
        if self.voice_controller.is_recognizing:
            self.manual_audio_button.setText("éŸ³å£°å…¥åŠ›åœæ­¢")
        else:
            self.manual_audio_button.setText("æ‰‹å‹•éŸ³å£°å…¥åŠ›")

    def _on_send_button_clicked(self):
        """é€ä¿¡ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ"""
        message = self.message_input.text().strip()
        if not message:
            self._add_chat_message("âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        self._add_chat_message(f"ğŸ‘¤ ã‚ãªãŸ: {message}")
        
        # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ã‚¯ãƒªã‚¢
        self.message_input.clear()
        
        # LLMã«é€ä¿¡
        self._add_chat_message("ğŸ¤– AI: è€ƒãˆä¸­...")
        self.voice_controller.chat_with_llm(message)

    def _on_model_changed(self, display_text):
        """ãƒ¢ãƒ‡ãƒ«é¸æŠå¤‰æ›´æ™‚ã®å‡¦ç†"""
        if display_text:
            selected_model = self.model_selector.currentData()
            if selected_model:
                self.voice_controller.llm_model = selected_model
                self._add_chat_message(f"ğŸ”„ LLMãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ã—ã¾ã—ãŸ: {display_text}")

    def _on_cancel_speech_button_clicked(self):
        """èª­ã¿ä¸Šã’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if self.voice_controller.cancel_speech():
            self._add_chat_message("ğŸ›‘ èª­ã¿ä¸Šã’ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        else:
            self._add_chat_message("âš ï¸ ã‚­ãƒ£ãƒ³ã‚»ãƒ«å¯èƒ½ãªèª­ã¿ä¸Šã’ãŒã‚ã‚Šã¾ã›ã‚“")

    def _add_chat_message(self, message):
        """ãƒãƒ£ãƒƒãƒˆãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
        current_text = self.chat_display.toPlainText()
        timestamp = time.strftime("%H:%M:%S")
        new_message = f"[{timestamp}] {message}\n"
        
        if current_text:
            self.chat_display.setPlainText(current_text + new_message)
        else:
            self.chat_display.setPlainText(new_message)
        
        # è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
        self.chat_display.verticalScrollBar().setValue(
            self.chat_display.verticalScrollBar().maximum()
        )

    def show(self):
        self.window.show()

    def cleanup(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # éŸ³å£°åˆæˆã‚­ãƒ£ãƒ³ã‚»ãƒ«
            if hasattr(self.voice_controller, 'cancel_speech'):
                self.voice_controller.cancel_speech()
            
            # éŸ³å£°èªè­˜åœæ­¢
            if hasattr(self.voice_controller, 'stop_recognition'):
                self.voice_controller.stop_recognition()
            
            # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºåœæ­¢
            if hasattr(self.wake_controller, 'detector') and self.wake_controller.detector:
                self.wake_controller.detector.stop_detection()
            
            # å„ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if hasattr(self.voice_controller, 'cleanup'):
                self.voice_controller.cleanup()
            
            print("âœ… MainWindow ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ MainWindow ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—è­¦å‘Š: {e}")

    def closeEvent(self, event):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¯ãƒ­ãƒ¼ã‚ºã‚¤ãƒ™ãƒ³ãƒˆ"""
        self.cleanup()
        event.accept()