from PySide6.QtUiTools import QUiLoader
from PySide6.QtCore import QFile, QObject, Signal
from PySide6.QtWidgets import QTextEdit, QPushButton
from wake_word import WakeWordDetector
from voice_synthesis import VoiceSynthesizer
from realtime_recognition import RealtimeRecognizer
import time
import threading

class WakeWordController(QObject):
    """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªUIæ›´æ–°ç”¨ï¼‰"""
    wake_word_detected = Signal(str, float)  # æ¤œå‡ºãƒ†ã‚­ã‚¹ãƒˆã¨ç¢ºä¿¡åº¦
    model_loaded = Signal()  # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ã‚·ã‚°ãƒŠãƒ«

    def __init__(self):
        super().__init__()
        self.detector = None  # é…å»¶åˆæœŸåŒ–
        self.is_detecting = False
        self.model_loading = False

    def preload_model(self):
        """ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰"""
        if self.model_loading or self.detector is not None:
            return

        self.model_loading = True
        print("ğŸš€ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰ä¸­...")

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        import threading
        load_thread = threading.Thread(target=self._preload_model_worker, daemon=True)
        load_thread.start()

    def _preload_model_worker(self):
        """ãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒ­ãƒ¼ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            from wake_word import WakeWordDetector
            self.detector = WakeWordDetector(self._on_wake_word_detected)
            # ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
            self.detector._init_model()
            self.model_loaded.emit()
            print("âœ… ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.model_loading = False

    def _get_detector(self):
        """æ¤œå‡ºå™¨ã‚’å–å¾—ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆã®ã¿ï¼‰"""
        if self.detector is None:
            if self.model_loading:
                print("â³ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
                return None
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãã®å ´ã§ãƒ­ãƒ¼ãƒ‰
                from wake_word import WakeWordDetector
                self.detector = WakeWordDetector(self._on_wake_word_detected)
        return self.detector

    def _on_wake_word_detected(self, text, confidence):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.wake_word_detected.emit(text, confidence)

    def toggle_detection(self):
        """æ¤œå‡ºã®é–‹å§‹/åœæ­¢ã‚’åˆ‡ã‚Šæ›¿ãˆ"""
        detector = self._get_detector()
        if detector is None:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒã¾ã ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        if self.is_detecting:
            detector.stop_detection()
            self.is_detecting = False
        else:
            detector.start_detection()
            self.is_detecting = True
        return self.is_detecting

class VoiceController(QObject):
    """éŸ³å£°å…¥å‡ºåŠ›ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼"""
    transcription_received = Signal(str, float)  # èªè­˜ãƒ†ã‚­ã‚¹ãƒˆã¨ç¢ºä¿¡åº¦
    silence_detected = Signal()  # æ²ˆé»™æ¤œå‡º
    model_loaded = Signal()  # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ã‚·ã‚°ãƒŠãƒ«
    speech_completed = Signal()  # éŸ³å£°åˆæˆå®Œäº†ã‚·ã‚°ãƒŠãƒ«

    def __init__(self):
        super().__init__()
        self.synthesizer = VoiceSynthesizer()
        self.recognizer = None  # é…å»¶åˆæœŸåŒ–
        self.is_recognizing = False
        self.is_speaking = False  # éŸ³å£°åˆæˆä¸­ãƒ•ãƒ©ã‚°
        self.model_loading = False

    def preload_model(self):
        """éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰"""
        if self.model_loading or self.recognizer is not None:
            return

        self.model_loading = True
        print("ğŸš€ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰ä¸­...")

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        import threading
        load_thread = threading.Thread(target=self._preload_model_worker, daemon=True)
        load_thread.start()

    def _preload_model_worker(self):
        """ãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒ­ãƒ¼ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            from realtime_recognition import RealtimeRecognizer
            self.recognizer = RealtimeRecognizer(
                transcription_callback=self._on_transcription,
                silence_callback=self._on_silence
            )
            # tqdmã®ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚’é…ã‚‰ã›ã‚‹
            print("âœ… éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æº–å‚™å®Œäº†")
            self.model_loaded.emit()
        except Exception as e:
            print(f"âŒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.model_loading = False

    def _get_recognizer(self):
        """èªè­˜å™¨ã‚’å–å¾—ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆã®ã¿ï¼‰"""
        if self.recognizer is None:
            if self.model_loading:
                print("â³ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
                return None
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãã®å ´ã§ãƒ­ãƒ¼ãƒ‰
                from realtime_recognition import RealtimeRecognizer
                self.recognizer = RealtimeRecognizer(
                    transcription_callback=self._on_transcription,
                    silence_callback=self._on_silence
                )
        return self.recognizer

    def _on_transcription(self, text, confidence):
        """éŸ³å£°èªè­˜çµæœã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.transcription_received.emit(text, confidence)

    def _on_silence(self):
        """æ²ˆé»™æ¤œå‡ºã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.silence_detected.emit()

    def speak_response(self, text: str):
        """å¿œç­”éŸ³å£°ã‚’éåŒæœŸã§å†ç”Ÿ"""
        if self.is_speaking:
            return  # æ—¢ã«ç™ºè©±ä¸­ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            
        self.is_speaking = True
        
        def _speak_async():
            try:
                self.synthesizer.speak_with_lipsync(text)
            finally:
                self.is_speaking = False
                self.speech_completed.emit()
        
        thread = threading.Thread(target=_speak_async, daemon=True)
        thread.start()

    def start_recognition(self):
        """éŸ³å£°èªè­˜ã‚’é–‹å§‹"""
        recognizer = self._get_recognizer()
        if recognizer is None:
            print("âŒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãŒã¾ã ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
            
        if self.is_speaking:
            print("â³ éŸ³å£°åˆæˆä¸­ã§ã™ã€‚åˆæˆå®Œäº†ã¾ã§å¾…æ©Ÿã—ã¾ã™...")
            # åˆæˆå®Œäº†ã‚’å¾…ã£ã¦ã‹ã‚‰èªè­˜ã‚’é–‹å§‹
            def _delayed_start():
                while self.is_speaking:
                    time.sleep(0.1)
                if not self.is_recognizing:
                    recognizer.start_recognition()
                    self.is_recognizing = True
            
            thread = threading.Thread(target=_delayed_start, daemon=True)
            thread.start()
            return
            
        if not self.is_recognizing:
            recognizer.start_recognition()
            self.is_recognizing = True

    def stop_recognition(self):
        """éŸ³å£°èªè­˜ã‚’åœæ­¢"""
        if self.is_recognizing and self.recognizer:
            self.recognizer.stop_recognition()
            self.is_recognizing = False

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # éŸ³å£°èªè­˜åœæ­¢
            self.stop_recognition()
            # VOICEVOXã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.synthesizer:
                self.synthesizer.cleanup()
        except Exception as e:
            print(f"âš ï¸ VoiceControllerã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—è­¦å‘Š: {e}")

class MainWindow:
    def __init__(self):
        # .uiãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        ui_file = QFile("src/main_window.ui")
        ui_file.open(QFile.ReadOnly)
        loader = QUiLoader()
        self.window = loader.load(ui_file)
        ui_file.close()

        # ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã¸ã®å‚ç…§ã‚’å–å¾—
        self.chat_display = self.window.findChild(QTextEdit, "chatDisplay")
        self.send_button = self.window.findChild(QPushButton, "sendButton")
        self.manual_audio_button = self.window.findChild(QPushButton, "manualAudioButton")
        self.wake_word_button = self.window.findChild(QPushButton, "wakeWordButton")

        # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–
        self.wake_controller = WakeWordController()
        self.wake_controller.wake_word_detected.connect(self._on_wake_word_detected)
        self.wake_controller.model_loaded.connect(self._on_model_loaded)

        # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰
        self.wake_controller.preload_model()

        # éŸ³å£°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–
        self.voice_controller = VoiceController()
        self.voice_controller.transcription_received.connect(self._on_transcription_received)
        self.voice_controller.silence_detected.connect(self._on_silence_detected)
        self.voice_controller.model_loaded.connect(self._on_voice_model_loaded)
        self.voice_controller.speech_completed.connect(self._on_speech_completed)

        # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰
        self.voice_controller.preload_model()

        # ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š
        self.wake_word_button.clicked.connect(self._on_wake_word_button_clicked)
        self.manual_audio_button.clicked.connect(self._on_manual_audio_button_clicked)

        # ãƒœã‚¿ãƒ³ã®åˆæœŸã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        self._setup_button_styles()

        # åˆæœŸçŠ¶æ…‹
        self._update_wake_word_button_text()

    def _setup_button_styles(self):
        """å…¨ãƒœã‚¿ãƒ³ã®åˆæœŸã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š"""
        # é€ä¿¡ãƒœã‚¿ãƒ³ï¼ˆé’è‰²ï¼‰
        self.send_button.setStyleSheet("""
            QPushButton {
                background-color: #339af0;
                color: white;
                border: 2px solid #228be6;
                border-radius: 5px;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #228be6;
            }
            QPushButton:pressed {
                background-color: #1c7ed6;
            }
        """)

        # æ‰‹å‹•éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸è‰²ï¼‰
        self.manual_audio_button.setStyleSheet("""
            QPushButton {
                background-color: #ff922b;
                color: white;
                border: 2px solid #fd7e14;
                border-radius: 5px;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #fd7e14;
            }
            QPushButton:pressed {
                background-color: #f76707;
            }
        """)

        # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®åˆæœŸã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆåœæ­¢ä¸­ï¼‰
        self._update_wake_word_button_text()

    def _on_wake_word_button_clicked(self):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ"""
        is_detecting = self.wake_controller.toggle_detection()
        if is_detecting is False and self.wake_controller.model_loading:
            self._add_chat_message("â³ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
            return
            
        self._update_wake_word_button_text()
        
        if is_detecting:
            self._add_chat_message("ğŸ¤ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        else:
            self._add_chat_message("ğŸ›‘ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’åœæ­¢ã—ã¾ã—ãŸ")

    def _on_model_loaded(self):
        """ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†æ™‚ã®å‡¦ç†"""
        self._add_chat_message("âœ… ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¾ã—ãŸ")

    def _on_voice_model_loaded(self):
        """éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†æ™‚ã®å‡¦ç†"""
        self._add_chat_message("âœ… éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¾ã—ãŸ")

    def _on_speech_completed(self):
        """éŸ³å£°åˆæˆå®Œäº†æ™‚ã®å‡¦ç†"""
        # éŸ³å£°åˆæˆå®Œäº†å¾Œã«éŸ³å£°èªè­˜ã‚’é–‹å§‹
        if not self.voice_controller.is_recognizing:
            self.voice_controller.start_recognition()
            self._add_chat_message("ğŸ¤ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")

    def _update_wake_word_button_text(self):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã¨è‰²ã‚’æ›´æ–°"""
        if self.wake_controller.is_detecting:
            self.wake_word_button.setText("ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥åœæ­¢")
            self.wake_word_button.setStyleSheet("""
                QPushButton {
                    background-color: #ff6b6b;
                    color: white;
                    border: 2px solid #ff5252;
                    border-radius: 5px;
                    padding: 5px;
                }
                QPushButton:hover {
                    background-color: #ff5252;
                }
                QPushButton:pressed {
                    background-color: #ff3838;
                }
            """)
        else:
            self.wake_word_button.setText("ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥é–‹å§‹")
            self.wake_word_button.setStyleSheet("""
                QPushButton {
                    background-color: #51cf66;
                    color: white;
                    border: 2px solid #40c057;
                    border-radius: 5px;
                    padding: 5px;
                }
                QPushButton:hover {
                    background-color: #40c057;
                }
                QPushButton:pressed {
                    background-color: #37b24d;
                }
            """)

    def _on_wake_word_detected(self, text, confidence):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºæ™‚ã®UIæ›´æ–°"""
        # å³åº§ã«æ¤œå‡ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        message = f"ğŸ¯ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: ã€Œ{text}ã€ (ç¢ºä¿¡åº¦: {confidence:.1f}%)"
        self._add_chat_message(message)

        # å¿œç­”éŸ³å£°ã‚’éåŒæœŸã§å†ç”Ÿï¼ˆåˆæˆå®Œäº†å¾Œã«éŸ³å£°èªè­˜ã‚’é–‹å§‹ï¼‰
        self.voice_controller.speak_response("ã¯ã„ï¼Œãªã‚“ã§ã™ã‹ï¼Ÿ")

    def _on_transcription_received(self, text, confidence):
        """éŸ³å£°èªè­˜çµæœå—ä¿¡æ™‚ã®å‡¦ç†"""
        message = f"ğŸ¯ èªè­˜: ã€Œ{text}ã€ (ç¢ºä¿¡åº¦: {confidence:.1f}%)"
        self._add_chat_message(message)

    def _on_silence_detected(self):
        """æ²ˆé»™æ¤œå‡ºæ™‚ã®å‡¦ç†"""
        self._add_chat_message("ğŸ”‡ æ²ˆé»™ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚è‡ªå‹•é€ä¿¡ã—ã¾ã™...")
        self.voice_controller.stop_recognition()
        self._on_send_button_clicked()

    def _on_manual_audio_button_clicked(self):
        """æ‰‹å‹•éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if self.voice_controller.model_loading:
            self._add_chat_message("â³ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
            return
            
        if self.voice_controller.is_recognizing:
            self.voice_controller.stop_recognition()
            self._add_chat_message("ğŸ›‘ éŸ³å£°å…¥åŠ›ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        else:
            self.voice_controller.start_recognition()
            self._add_chat_message("ğŸ¤ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")

        self._update_manual_audio_button_text()

    def _update_manual_audio_button_text(self):
        """æ‰‹å‹•éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°"""
        if self.voice_controller.is_recognizing:
            self.manual_audio_button.setText("éŸ³å£°å…¥åŠ›åœæ­¢")
        else:
            self.manual_audio_button.setText("æ‰‹å‹•éŸ³å£°å…¥åŠ›")

    def _on_send_button_clicked(self):
        """é€ä¿¡ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆä»®å®Ÿè£…ï¼‰"""
        self._add_chat_message("ğŸ“¤ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¾ã—ãŸï¼ˆLLMå‡¦ç†ã¯æœªå®Ÿè£…ï¼‰")

    def _add_chat_message(self, message):
        """ãƒãƒ£ãƒƒãƒˆãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
        current_text = self.chat_display.toPlainText()
        timestamp = time.strftime("%H:%M:%S")
        new_message = f"[{timestamp}] {message}\n"
        
        if current_text:
            self.chat_display.setPlainText(current_text + new_message)
        else:
            self.chat_display.setPlainText(new_message)
        
        # è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
        self.chat_display.verticalScrollBar().setValue(
            self.chat_display.verticalScrollBar().maximum()
        )

    def show(self):
        self.window.show()