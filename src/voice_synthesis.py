#!/usr/bin/env python3
"""
VOICEVOXéŸ³å£°åˆæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å¯¾å¿œï¼‰
PySide6 UIçµ±åˆç”¨ã«æœ€é©åŒ–
"""

import os
import tempfile
import subprocess
import threading
import time
from voicevox_core.blocking import Onnxruntime, OpenJtalk, Synthesizer, VoiceModelFile

# ã‚·ãƒªã‚¦ã‚¹è¡¨æƒ…åˆ¶å¾¡API
SIRIUS_API_URL = "http://localhost:8080"

class VoiceSynthesizer:
    def __init__(self):
        self.synthesizer = None
        self._init_synthesizer()

        # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–¢é€£ã®åˆæœŸåŒ–
        self.style_id = 54
        self.speed_scale = 1.0
        self.pitch_scale = 0.0
        self.intonation_scale = 0.9

    def _init_synthesizer(self):
        """Synthesizerã‚’åˆæœŸåŒ–"""
        try:
            # VOICEVOX COREã®åˆæœŸåŒ–
            voicevox_onnxruntime_path = "voicevox_core/onnxruntime/lib/" + Onnxruntime.LIB_VERSIONED_FILENAME
            open_jtalk_dict_dir = "voicevox_core/dict/open_jtalk_dic_utf_8-1.11"

            self.synthesizer = Synthesizer(
                Onnxruntime.load_once(filename=voicevox_onnxruntime_path),
                OpenJtalk(open_jtalk_dict_dir)
            )

            # éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆ13.vvmã‚’ä½¿ç”¨ï¼‰
            with VoiceModelFile.open("voicevox_core/models/vvms/13.vvm") as model:
                self.synthesizer.load_voice_model(model)

            print("âœ… VOICEVOXåˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            print(f"âŒ VOICEVOXåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.synthesizer = None

    def speak_with_lipsync(self, text: str):
        """éŸ³å£°åˆæˆ + ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯"""
        if not self.synthesizer:
            print("âŒ SynthesizerãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False

        try:
            print(f"ğŸ¤ åˆæˆ: ã€Œ{text}ã€ (é€Ÿåº¦: {self.speed_scale}x, ã‚¹ã‚¿ã‚¤ãƒ«: {self.style_id})")

            # AudioQueryä½œæˆ
            audio_query = self.synthesizer.create_audio_query(text, self.style_id)
            self._set_speed_scale(audio_query, self.speed_scale)

            # éŸ³å£°åˆæˆ
            wav_data = self.synthesizer.synthesis(audio_query, self.style_id)
            print("âœ… éŸ³å£°åˆæˆæˆåŠŸ")

            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Ÿè¡Œ
            self._perform_lipsync(audio_query, wav_data, self.speed_scale)

            return True

        except Exception as e:
            print(f"âŒ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _set_speed_scale(self, audio_query, speed_scale: float):
        """AudioQueryã«é€Ÿåº¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚’è¨­å®š"""
        if hasattr(audio_query, 'speed_scale'):
            audio_query.speed_scale = speed_scale

    def _perform_lipsync(self, audio_query, wav_data, speed_scale: float):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Ÿè¡Œ"""
        # å£å½¢çŠ¶ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ
        mouth_sequence = self._get_mouth_shape_sequence(audio_query, speed_scale)

        print("ğŸ“ å£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹:")
        for i, (seq_time, mouth_shape, duration) in enumerate(mouth_sequence[:10]):
            print(".2f")
        if len(mouth_sequence) > 10:
            print(f"  ... ä»–{len(mouth_sequence) - 10}å€‹")

        # åŒæœŸã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ
        audio_start_event = threading.Event()

        # éŸ³å£°å†ç”Ÿã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        audio_thread = threading.Thread(
            target=self._play_audio_precise,
            args=(wav_data, audio_start_event),
            daemon=True
        )
        audio_thread.start()

        # éŸ³å£°å†ç”Ÿé–‹å§‹ã‚’å¾…æ©Ÿ
        audio_start_event.wait()
        actual_audio_start = time.time()

        print(".6f")

        # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Ÿè¡Œ
        timing_stats = {'perfect': 0, 'good': 0, 'poor': 0}
        first_mouth_pattern = True

        for seq_time, mouth_shape, duration in mouth_sequence:
            # ç›®æ¨™æ™‚é–“ = éŸ³å£°é–‹å§‹æ™‚é–“ + ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ™‚é–“
            target_time = actual_audio_start + seq_time

            # é«˜ç²¾åº¦ã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¶å¾¡
            while True:
                current_time = time.time()
                time_to_target = target_time - current_time

                if time_to_target <= 0.0001:
                    break
                elif time_to_target > 0:
                    if time_to_target < 0.001:
                        pass
                    else:
                        time.sleep(max(0.0001, time_to_target - 0.0005))
                else:
                    break

            # å£ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š
            server_pattern = f"mouth_{mouth_shape}" if mouth_shape else None
            if server_pattern:
                if first_mouth_pattern:
                    success = self._set_mouth_pattern(server_pattern)
                    if not success:
                        print(f"âš ï¸ å£ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šå¤±æ•—: {server_pattern}")
                    first_mouth_pattern = False
                else:
                    self._set_mouth_pattern_async(server_pattern)

                # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç²¾åº¦è©•ä¾¡
                actual_time = time.time()
                timing_error_ms = (actual_time - target_time) * 1000

                if abs(timing_error_ms) <= 5:
                    sync_indicator = "âœ“"
                    timing_stats['perfect'] += 1
                elif abs(timing_error_ms) <= 15:
                    sync_indicator = "~"
                    timing_stats['good'] += 1
                else:
                    sync_indicator = "âš "
                    timing_stats['poor'] += 1

                print(".1f")

        # çµ±è¨ˆè¡¨ç¤º
        total_patterns = timing_stats['perfect'] + timing_stats['good'] + timing_stats['poor']
        if total_patterns > 0:
            perfect_rate = timing_stats['perfect'] / total_patterns * 100
            print(".1f")

        # çµ‚äº†æ™‚ã«å£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
        time.sleep(0.2)
        self._set_mouth_pattern_async(None)
        print("âœ… ç™ºè©±å®Œäº†\n")

    def _get_mouth_shape_sequence(self, audio_query, speed_scale: float):
        """AudioQueryã‹ã‚‰å£å½¢çŠ¶ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        try:
            phoneme_timeline = []
            current_time = 0.0

            # accent_phrasesã‹ã‚‰éŸ³éŸ»æƒ…å ±ã‚’æŠ½å‡º
            if hasattr(audio_query, 'accent_phrases'):
                for accent_phrase in audio_query.accent_phrases:
                    if hasattr(accent_phrase, 'moras'):
                        for mora in accent_phrase.moras:
                            # å­éŸ³å‡¦ç†
                            if hasattr(mora, 'consonant') and mora.consonant:
                                consonant_phoneme = mora.consonant
                                consonant_duration = getattr(mora, 'consonant_length', 0.1) or 0.1
                                consonant_duration /= speed_scale

                                mouth_shape = self._phoneme_to_mouth_shape(consonant_phoneme)
                                phoneme_timeline.append((current_time, mouth_shape, consonant_duration))
                                current_time += consonant_duration

                            # æ¯éŸ³å‡¦ç†
                            if hasattr(mora, 'vowel') and mora.vowel:
                                vowel_phoneme = mora.vowel
                                vowel_duration = getattr(mora, 'vowel_length', 0.1) or 0.1
                                vowel_duration /= speed_scale

                                mouth_shape = self._phoneme_to_mouth_shape(vowel_phoneme)
                                phoneme_timeline.append((current_time, mouth_shape, vowel_duration))
                                current_time += vowel_duration

                    # ãƒãƒ¼ã‚ºå‡¦ç†
                    if hasattr(accent_phrase, 'pause_mora') and accent_phrase.pause_mora:
                        pause_duration = getattr(accent_phrase.pause_mora, 'vowel_length', 0.0) or 0.0
                        if pause_duration > 0:
                            pause_duration /= speed_scale
                            phoneme_timeline.append((current_time, None, pause_duration))
                            current_time += pause_duration

            return phoneme_timeline

        except Exception as e:
            print(f"âŒ éŸ³éŸ»è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _phoneme_to_mouth_shape(self, phoneme):
        """éŸ³éŸ»ã‹ã‚‰å£å½¢çŠ¶ã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
        phoneme_to_mouth = {
            'a': 'a', 'i': 'i', 'u': 'o', 'e': 'a', 'o': 'o',
            'k': 'a', 'g': 'a', 's': 'i', 'z': 'i', 't': 'a', 'd': 'a',
            'n': 'o', 'h': 'o', 'b': 'o', 'p': 'o', 'm': 'o', 'y': 'a',
            'r': 'a', 'w': 'o', 'f': 'o', 'v': 'o', 'ch': 'i', 'sh': 'i',
            'j': 'i', 'ts': 'a', 'sil': None, 'pau': None, 'cl': None,
            'q': None, 'N': 'o'
        }
        return phoneme_to_mouth.get(phoneme, 'a')

    def _set_mouth_pattern(self, pattern):
        """ã‚·ãƒªã‚¦ã‚¹ã®å£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨­å®šï¼ˆåŒæœŸç‰ˆï¼‰"""
        try:
            import urllib.request
            import json

            data = json.dumps({"mouth_pattern": pattern}).encode('utf-8')
            req = urllib.request.Request(
                f"{SIRIUS_API_URL}/mouth_pattern",
                data=data,
                headers={'Content-Type': 'application/json'}
            )
            with urllib.request.urlopen(req, timeout=0.5) as response:
                return response.getcode() == 200
        except Exception as e:
            print(f"âŒ å£ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _set_mouth_pattern_async(self, pattern):
        """ã‚·ãƒªã‚¦ã‚¹ã®å£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’éåŒæœŸè¨­å®š"""
        def _set_pattern():
            try:
                import urllib.request
                import json

                data = json.dumps({"mouth_pattern": pattern}).encode('utf-8')
                req = urllib.request.Request(
                    f"{SIRIUS_API_URL}/mouth_pattern",
                    data=data,
                    headers={'Content-Type': 'application/json'}
                )
                with urllib.request.urlopen(req, timeout=0.05) as response:
                    pass
            except:
                pass

        thread = threading.Thread(target=_set_pattern, daemon=True)
        thread.start()

    def _play_audio_precise(self, wav_data, start_event):
        """éŸ³å£°ã‚’å†ç”Ÿï¼ˆç²¾å¯†åŒæœŸç‰ˆï¼‰"""
        try:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_file.write(wav_data)
                temp_file_path = temp_file.name

            # å†ç”Ÿé–‹å§‹ã‚’é€šçŸ¥
            start_event.set()

            # afplayã§å†ç”Ÿ
            process = subprocess.Popen(
                ['afplay', temp_file_path],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            process.wait()
            os.unlink(temp_file_path)
        except Exception as e:
            print(f"âŒ éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")

    def speak_response(self, text: str):
        """å¿œç­”éŸ³å£°ã‚’å†ç”Ÿï¼ˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ä»˜ãï¼‰"""
        return self.speak_with_lipsync(text)

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if self.synthesizer:
                # VOICEVOX Coreã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                # Synthesizerã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ˜ç¤ºçš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                self.synthesizer = None
                print("âœ… VOICEVOXãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ VOICEVOXã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—è­¦å‘Š: {e}")