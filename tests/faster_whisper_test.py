#!/usr/bin/env python3
"""
Faster Whisper éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§æ“ä½œï¼ˆstart: éŒ²éŸ³é–‹å§‹, stop: éŒ²éŸ³çµ‚äº†ãƒ»èªè­˜, quit: çµ‚äº†ï¼‰
"""

import os
import tempfile
import pyaudio
import wave
import numpy as np
import threading
import time
import sys
import select
from faster_whisper import WhisperModel

# è¨­å®š
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000  # Whisperæ¨å¥¨ã®16kHz

def calculate_confidence_metrics(segments, info):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ä¿¡é ¼åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
    try:
        word_confidences = []
        word_count = 0
        total_duration = 0
        
        for segment in segments:
            if hasattr(segment, 'words') and segment.words:
                # å˜èªãƒ¬ãƒ™ãƒ«ã®ä¿¡é ¼åº¦ã‚’å–å¾—
                for word in segment.words:
                    if hasattr(word, 'probability') and word.probability is not None:
                        # å¯¾æ•°ç¢ºç‡ã‚’ä¿¡é ¼åº¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã«å¤‰æ›
                        confidence = min(100.0, max(0.0, (word.probability + 5.0) / 5.0 * 100))
                        word_confidences.append(confidence)
                        word_count += 1
        
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®æƒ…å ±
            if hasattr(segment, 'avg_logprob') and segment.avg_logprob is not None:
                # å¹³å‡å¯¾æ•°ç¢ºç‡ã‚’ä¿¡é ¼åº¦ã«å¤‰æ›
                segment_confidence = min(100.0, max(0.0, (segment.avg_logprob + 5.0) / 5.0 * 100))
                word_confidences.append(segment_confidence)
        
            total_duration += getattr(segment, 'end', 0) - getattr(segment, 'start', 0)
        
        # å…¨ä½“çš„ãªä¿¡é ¼åº¦ã‚’è¨ˆç®—
        if word_confidences:
            overall_confidence = sum(word_confidences) / len(word_confidences)
            min_confidence = min(word_confidences)
            max_confidence = max(word_confidences)
            std_confidence = (sum((x - overall_confidence) ** 2 for x in word_confidences) / len(word_confidences)) ** 0.5
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¨€èªç¢ºç‡ã‚’ä½¿ç”¨
            overall_confidence = info.language_probability * 100 if hasattr(info, 'language_probability') else 50.0
            min_confidence = max_confidence = overall_confidence
            std_confidence = 0.0
            word_count = len(segments)
        
        return {
            'overall_confidence': overall_confidence,
            'min_confidence': min_confidence,
            'max_confidence': max_confidence,
            'std_confidence': std_confidence,
            'word_count': word_count,
            'segment_count': len(segments),
            'audio_duration': getattr(info, 'duration', total_duration),
            'language_probability': getattr(info, 'language_probability', 0.0) * 100,
            'word_confidences': word_confidences
        }
        
    except Exception as e:
        print(f"âš ï¸ ä¿¡é ¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return {
            'overall_confidence': 50.0,
            'min_confidence': 50.0,
            'max_confidence': 50.0,
            'std_confidence': 0.0,
            'word_count': 0,
            'segment_count': len(segments) if segments else 0,
            'audio_duration': 0.0,
            'language_probability': 50.0,
            'word_confidences': []
        }

class AudioRecorder:
    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.frames = []
        self.is_recording = False

    def start_recording(self):
        if self.is_recording:
            print("ã™ã§ã«éŒ²éŸ³ä¸­ã§ã™ã€‚")
            return

        self.frames = []
        self.stream = self.audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK
        )
        self.is_recording = True
        print("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚'stop' ã¨å…¥åŠ›ã—ã¦çµ‚äº†ã—ã¦ãã ã•ã„ã€‚")

    def stop_recording(self):
        if not self.is_recording:
            print("éŒ²éŸ³ä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None

        self.is_recording = False
        self.stream.stop_stream()
        self.stream.close()

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            temp_filename = temp_file.name
            wf = wave.open(temp_filename, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.audio.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(self.frames))
            wf.close()

        print("éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚éŸ³å£°èªè­˜ä¸­...")
        return temp_filename

    def record_chunk(self):
        if self.is_recording:
            try:
                data = self.stream.read(CHUNK, exception_on_overflow=False)
                self.frames.append(data)
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                import numpy as np
                audio_data = np.frombuffer(data, dtype=np.int16)
                if len(audio_data) > 0:
                    volume = np.sqrt(np.mean(audio_data.astype(np.float64)**2))
                    if np.isnan(volume):
                        volume = 0
                else:
                    volume = 0
                if len(self.frames) % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¡¨ç¤º
                    print(f"éŒ²éŸ³ä¸­... ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(self.frames)}, éŸ³é‡: {volume:.0f}")
            except Exception as e:
                print(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")

    def close(self):
        self.audio.terminate()

def list_audio_devices():
    """åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º"""
    print("\nğŸ¤ åˆ©ç”¨å¯èƒ½ãªéŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹:")
    p = pyaudio.PyAudio()
    for i in range(p.get_device_count()):
        info = p.get_device_info_by_index(i)
        if info['maxInputChannels'] > 0:
            print(f"  {i}: {info['name']} (ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {info['maxInputChannels']}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {info['defaultSampleRate']}Hz)")
    p.terminate()
    print()

def main():
    print("ğŸ¤ Faster Whisper éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ")
    print("ã‚³ãƒãƒ³ãƒ‰: start (éŒ²éŸ³é–‹å§‹), stop (éŒ²éŸ³çµ‚äº†ãƒ»èªè­˜), quit (çµ‚äº†)")
    print("-" * 50)
    
    # éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º
    list_audio_devices()

    # Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ã‚ºã¯mediumã§é«˜ç²¾åº¦ï¼‰
    print("Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = WhisperModel("medium", device="cpu", compute_type="int8")
    print("ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    recorder = AudioRecorder()

    try:
        import threading
        import time
        import sys
        import select
        
        def recording_thread():
            """éŒ²éŸ³ç”¨ã‚¹ãƒ¬ãƒƒãƒ‰"""
            while recorder.is_recording:
                recorder.record_chunk()
                time.sleep(0.01)  # 10mså¾…æ©Ÿ
        
        while True:
            # éŒ²éŸ³ä¸­ã§ã‚‚ã‚³ãƒãƒ³ãƒ‰å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹
            if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
                command = input("ã‚³ãƒãƒ³ãƒ‰: ").strip().lower()
            else:
                command = input("ã‚³ãƒãƒ³ãƒ‰: ").strip().lower()

            if command == "start":
                if not recorder.is_recording:
                    recorder.start_recording()
                    # éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
                    thread = threading.Thread(target=recording_thread, daemon=True)
                    thread.start()
                else:
                    print("ã™ã§ã«éŒ²éŸ³ä¸­ã§ã™ã€‚")
                    
            elif command == "stop":
                if recorder.is_recording:
                    temp_file = recorder.stop_recording()
                    if temp_file:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
                        file_size = os.path.getsize(temp_file)
                        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes")
                        
                        if file_size < 1000:  # 1KBæœªæº€ã®å ´åˆã¯è­¦å‘Š
                            print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã¾ã™ã€‚ãƒã‚¤ã‚¯ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        
                        # éŸ³å£°èªè­˜ï¼ˆsync_siriusface.pyã‚’å‚è€ƒã«ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
                        print("éŸ³å£°èªè­˜å‡¦ç†ä¸­...")
                        segments, info = model.transcribe(
                            temp_file,
                            language="ja",              # æ—¥æœ¬èªæŒ‡å®š
                            beam_size=5,                # ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚µã‚¤ã‚ºï¼ˆç²¾åº¦å‘ä¸Šï¼‰
                            temperature=0.0,            # æ±ºå®šè«–çš„å‡ºåŠ›ï¼ˆç²¾åº¦å‘ä¸Šï¼‰
                            compression_ratio_threshold=2.4,  # åœ§ç¸®ç‡é–¾å€¤ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
                            log_prob_threshold=-1.0,    # ç¢ºç‡é–¾å€¤ï¼ˆä½ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
                            no_speech_threshold=0.2,    # ç„¡éŸ³åˆ¤å®šé–¾å€¤ã‚’ç·©ãï¼ˆ0.6â†’0.2ï¼‰
                            condition_on_previous_text=False,  # å‰ã®ãƒ†ã‚­ã‚¹ãƒˆã«ä¾å­˜ã—ãªã„
                            initial_prompt="ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚",  # æ—¥æœ¬èªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                            word_timestamps=True,       # å˜èªãƒ¬ãƒ™ãƒ«ã®ä¿¡é ¼åº¦å–å¾—ã®ãŸã‚æœ‰åŠ¹åŒ–
                            vad_filter=True,           # Voice Activity Detectionï¼ˆéŸ³å£°åŒºé–“æ¤œå‡ºï¼‰
                            vad_parameters=dict(min_silence_duration_ms=250)  # ç„¡éŸ³åŒºé–“ã‚’çŸ­ãï¼ˆ500â†’250msï¼‰
                        )
                        
                        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                        segments_list = list(segments)
                        text = "".join(segment.text for segment in segments_list).strip()
                        
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
                        print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments_list)}")
                        for i, segment in enumerate(segments_list):
                            print(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {i+1}: '{segment.text}' (é–‹å§‹: {segment.start:.2f}s, çµ‚äº†: {segment.end:.2f}s)")
                        
                        # ä¿¡é ¼åº¦æƒ…å ±ã‚’è¨ˆç®—
                        confidence_info = calculate_confidence_metrics(segments_list, info)
                        
                        print(f"èªè­˜çµæœ: {text}")
                        print(f"è¨€èª: {info.language} (ç¢ºä¿¡åº¦: {info.language_probability:.2f})")
                        print(f"éŸ³å£°æ™‚é–“: {info.duration:.2f}ç§’")
                        print(f"èªè­˜ç²¾åº¦: {confidence_info['overall_confidence']:.1f}% (å˜èªæ•°: {confidence_info['word_count']})")
                        
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                        os.unlink(temp_file)
                    print("-" * 50)
                else:
                    print("éŒ²éŸ³ä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    
            elif command == "quit":
                if recorder.is_recording:
                    recorder.stop_recording()
                print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            else:
                print("ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚start, stop, quit ã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    except KeyboardInterrupt:
        print("\nãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    finally:
        recorder.close()

if __name__ == "__main__":
    main()