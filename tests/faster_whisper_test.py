#!/usr/bin/env python3
"""
Faster Whisper éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§æ“ä½œï¼ˆstart: éŒ²éŸ³é–‹å§‹, stop: éŒ²éŸ³çµ‚äº†ãƒ»èªè­˜, quit: çµ‚äº†ï¼‰
"""

import os
import tempfile
import pyaudio
import wave
import numpy as np
import time
import threading
from faster_whisper import WhisperModel

# è¨­å®š
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000  # Whisperæ¨å¥¨ã®16kHz

def calculate_confidence_metrics(segments, info):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ä¿¡é ¼åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
    try:
        word_confidences = []
        word_count = 0
        total_duration = 0
        
        for segment in segments:
            if hasattr(segment, 'words') and segment.words:
                # å˜èªãƒ¬ãƒ™ãƒ«ã®ä¿¡é ¼åº¦ã‚’å–å¾—
                for word in segment.words:
                    if hasattr(word, 'probability') and word.probability is not None:
                        # å¯¾æ•°ç¢ºç‡ã‚’ä¿¡é ¼åº¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã«å¤‰æ›
                        confidence = min(100.0, max(0.0, (word.probability + 5.0) / 5.0 * 100))
                        word_confidences.append(confidence)
                        word_count += 1
        
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®æƒ…å ±
            if hasattr(segment, 'avg_logprob') and segment.avg_logprob is not None:
                # å¹³å‡å¯¾æ•°ç¢ºç‡ã‚’ä¿¡é ¼åº¦ã«å¤‰æ›
                segment_confidence = min(100.0, max(0.0, (segment.avg_logprob + 5.0) / 5.0 * 100))
                word_confidences.append(segment_confidence)
        
            total_duration += getattr(segment, 'end', 0) - getattr(segment, 'start', 0)
        
        # å…¨ä½“çš„ãªä¿¡é ¼åº¦ã‚’è¨ˆç®—
        if word_confidences:
            overall_confidence = sum(word_confidences) / len(word_confidences)
            min_confidence = min(word_confidences)
            max_confidence = max(word_confidences)
            std_confidence = (sum((x - overall_confidence) ** 2 for x in word_confidences) / len(word_confidences)) ** 0.5
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¨€èªç¢ºç‡ã‚’ä½¿ç”¨
            overall_confidence = info.language_probability * 100 if hasattr(info, 'language_probability') else 50.0
            min_confidence = max_confidence = overall_confidence
            std_confidence = 0.0
            word_count = len(segments)
        
        return {
            'overall_confidence': overall_confidence,
            'min_confidence': min_confidence,
            'max_confidence': max_confidence,
            'std_confidence': std_confidence,
            'word_count': word_count,
            'segment_count': len(segments),
            'audio_duration': getattr(info, 'duration', total_duration),
            'language_probability': getattr(info, 'language_probability', 0.0) * 100,
            'word_confidences': word_confidences
        }
        
    except Exception as e:
        print(f"âš ï¸ ä¿¡é ¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return {
            'overall_confidence': 50.0,
            'min_confidence': 50.0,
            'max_confidence': 50.0,
            'std_confidence': 0.0,
            'word_count': 0,
            'segment_count': len(segments) if segments else 0,
            'audio_duration': 0.0,
            'language_probability': 50.0,
            'word_confidences': []
        }

class AudioRecorder:
    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.frames = []
        self.is_recording = False

    def start_recording(self):
        if self.is_recording:
            print("ã™ã§ã«éŒ²éŸ³ä¸­ã§ã™ã€‚")
            return

        self.frames = []
        self.stream = self.audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK
        )
        self.is_recording = True
        print("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚'stop' ã¨å…¥åŠ›ã—ã¦çµ‚äº†ã—ã¦ãã ã•ã„ã€‚")
        
        # éŒ²éŸ³é–‹å§‹å¾Œã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç¶™ç¶šå–å¾—
        import threading
        self.recording_thread = threading.Thread(target=self._continuous_recording, daemon=True)
        self.recording_thread.start()

    def _continuous_recording(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éŒ²éŸ³ã‚’ç¶™ç¶šã™ã‚‹"""
        frame_count = 0
        while self.is_recording:
            try:
                data = self.stream.read(CHUNK, exception_on_overflow=False)
                self.frames.append(data)
                frame_count += 1
                
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                import numpy as np
                audio_data = np.frombuffer(data, dtype=np.int16)
                if len(audio_data) > 0:
                    volume = np.sqrt(np.mean(audio_data.astype(np.float64)**2))
                    if np.isnan(volume):
                        volume = 0
                else:
                    volume = 0
                    
                if frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¡¨ç¤º
                    print(f"éŒ²éŸ³ä¸­... ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}, éŸ³é‡: {volume:.0f}")
            except Exception as e:
                print(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
                break
            import time
            time.sleep(0.01)  # 10mså¾…æ©Ÿ

    def stop_recording(self):
        if not self.is_recording:
            print("éŒ²éŸ³ä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None

        self.is_recording = False
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…ã¤
        if hasattr(self, 'recording_thread') and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=1.0)
        
        self.stream.stop_stream()
        self.stream.close()

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            temp_filename = temp_file.name
            wf = wave.open(temp_filename, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.audio.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(self.frames))
            wf.close()

        print("éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚éŸ³å£°èªè­˜ä¸­...")
        return temp_filename

    def record_chunk(self):
        if self.is_recording:
            try:
                data = self.stream.read(CHUNK, exception_on_overflow=False)
                self.frames.append(data)
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                import numpy as np
                audio_data = np.frombuffer(data, dtype=np.int16)
                if len(audio_data) > 0:
                    volume = np.sqrt(np.mean(audio_data.astype(np.float64)**2))
                    if np.isnan(volume):
                        volume = 0
                else:
                    volume = 0
                if len(self.frames) % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¡¨ç¤º
                    print(f"éŒ²éŸ³ä¸­... ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(self.frames)}, éŸ³é‡: {volume:.0f}")
            except Exception as e:
                print(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")

    def close(self):
        self.audio.terminate()

def list_audio_devices():
    """åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º"""
    print("\nğŸ¤ åˆ©ç”¨å¯èƒ½ãªéŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹:")
    p = pyaudio.PyAudio()
    for i in range(p.get_device_count()):
        info = p.get_device_info_by_index(i)
        if info['maxInputChannels'] > 0:
            print(f"  {i}: {info['name']} (ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {info['maxInputChannels']}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {info['defaultSampleRate']}Hz)")
    p.terminate()
    print()

def main():
    print("ğŸ¤ Faster Whisper éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ")
    print("ã‚³ãƒãƒ³ãƒ‰: start (éŒ²éŸ³é–‹å§‹), stop (éŒ²éŸ³çµ‚äº†ãƒ»èªè­˜), quit (çµ‚äº†)")
    print("-" * 50)
    
    # éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º
    list_audio_devices()

    # Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆé«˜é€ŸåŒ–è¨­å®šï¼‰
    print("Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = WhisperModel(
        "medium",  # ã“ã“ã¯ã‚†ãšã‚Œãªã„
        device="cpu",
        compute_type="int8",
        cpu_threads=8,  # CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’8ã«å¢—åŠ ï¼ˆ10ã‚³ã‚¢ä¸­ï¼‰
        num_workers=1
    )
    print("ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    recorder = AudioRecorder()

    try:
        import time
        
        while True:
            command = input("ã‚³ãƒãƒ³ãƒ‰: ").strip().lower()

            if command == "start":
                if not recorder.is_recording:
                    recorder.start_recording()
                    print("éŒ²éŸ³ä¸­ã§ã™... 'stop'ã¨å…¥åŠ›ã—ã¦çµ‚äº†ã—ã¦ãã ã•ã„")
                else:
                    print("ã™ã§ã«éŒ²éŸ³ä¸­ã§ã™ã€‚")
                    
            elif command == "stop":
                if recorder.is_recording:
                    # stopã‚³ãƒãƒ³ãƒ‰å…¥åŠ›æ™‚ã®æ™‚é–“ã‚’è¨˜éŒ²
                    stop_command_time = time.time()
                    
                    temp_file = recorder.stop_recording()
                    if temp_file:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
                        file_size = os.path.getsize(temp_file)
                        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes")
                        
                        if file_size < 1000:  # 1KBæœªæº€ã®å ´åˆã¯è­¦å‘Š
                            print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã¾ã™ã€‚ãƒã‚¤ã‚¯ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        
                        # éŸ³å£°èªè­˜ï¼ˆsync_siriusface.pyã‚’å‚è€ƒã«ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
                        print("éŸ³å£°èªè­˜å‡¦ç†ä¸­...")
                        
                        try:
                            segments, info = model.transcribe(
                                temp_file,
                                language="ja",              # æ—¥æœ¬èªæŒ‡å®š
                                beam_size=1,                # ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚’1ã«è¨­å®šï¼ˆgreedy decodingï¼‰ã§æœ€å¤§é€Ÿåº¦
                                temperature=0.0,            # æ±ºå®šè«–çš„å‡ºåŠ›
                                compression_ratio_threshold=2.0,  # åœ§ç¸®ç‡é–¾å€¤ã‚’ç·©ãï¼ˆ2.4â†’2.0ï¼‰ã§å‡¦ç†è»½æ¸›
                                log_prob_threshold=-0.8,    # ç¢ºç‡é–¾å€¤ã‚’ç·©ãï¼ˆ-1.0â†’-0.8ï¼‰ã§é«˜é€ŸåŒ–
                                no_speech_threshold=0.4,    # ç„¡éŸ³åˆ¤å®šã‚’ã•ã‚‰ã«ç·©ãï¼ˆ0.3â†’0.4ï¼‰
                                condition_on_previous_text=False,
                                initial_prompt="ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚",
                                word_timestamps=False,
                                vad_filter=True,
                                vad_parameters=dict(
                                    min_silence_duration_ms=800,  # ç„¡éŸ³åŒºé–“ã‚’é•·ãï¼ˆ500â†’800msï¼‰ã§å‡¦ç†è»½æ¸›
                                    speech_pad_ms=50,       # éŸ³å£°ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã•ã‚‰ã«çŸ­ç¸®
                                    threshold=0.5           # VADé–¾å€¤ã‚’é«˜ãã—ã¦ã‚ˆã‚Šç©æ¥µçš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                                )
                            )
                            
                            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                            segments_list = list(segments)
                            text = "".join(segment.text for segment in segments_list).strip()
                            
                            # stopã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰èªè­˜å®Œäº†ã¾ã§ã®æ™‚é–“ã‚’è¨ˆç®—
                            recognition_end = time.time()
                            total_time_from_stop = recognition_end - stop_command_time
                            
                            # ç°¡æ½”ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰
                            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments_list)}")
                            
                            # ä¿¡é ¼åº¦æƒ…å ±ã‚’è¨ˆç®—ï¼ˆç°¡ç•¥åŒ–ï¼‰
                            confidence_info = calculate_confidence_metrics(segments_list, info)
                            
                            print(f"èªè­˜çµæœ: {text}")
                            print(f"è¨€èª: {info.language} (ç¢ºä¿¡åº¦: {info.language_probability:.2f})")
                            print(f"éŸ³å£°æ™‚é–“: {info.duration:.2f}ç§’")
                            print(f"èªè­˜ç²¾åº¦: {confidence_info['overall_confidence']:.1f}% (å˜èªæ•°: {confidence_info['word_count']})")
                            print(f"â±ï¸  stopã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰å®Œäº†ã¾ã§: {total_time_from_stop:.2f}ç§’")
                            
                            # å‡¦ç†åŠ¹ç‡ã®è¨ˆç®—
                            if info.duration > 0:
                                processing_ratio = total_time_from_stop / info.duration
                                if processing_ratio < 1.0:
                                    print(f"âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿‚æ•°: {processing_ratio:.2f}x (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ˆã‚Š {1/processing_ratio:.1f}å€é«˜é€Ÿ)")
                                else:
                                    print(f"ğŸŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿‚æ•°: {processing_ratio:.2f}x (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ˆã‚Š {processing_ratio:.1f}å€ä½é€Ÿ)")
                            
                        except Exception as transcribe_error:
                            print(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {transcribe_error}")
                        
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                        try:
                            os.unlink(temp_file)
                        except:
                            pass
                    print("-" * 50)
                else:
                    print("éŒ²éŸ³ä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    
            elif command == "quit":
                if recorder.is_recording:
                    recorder.stop_recording()
                print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            else:
                print("ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚start, stop, quit ã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    except KeyboardInterrupt:
        print("\nãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    finally:
        recorder.close()

if __name__ == "__main__":
    main()