#!/usr/bin/env python3
"""
Faster Whisper éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§æ“ä½œï¼ˆstart: éŒ²éŸ³é–‹å§‹, stop: éŒ²éŸ³çµ‚äº†ãƒ»èªè­˜, quit: çµ‚äº†ï¼‰
"""

import os
import tempfile
import pyaudio
import wave
import numpy as np
import time
import threading
from faster_whisper import WhisperModel

# =============================================================================
# ğŸš€ é«˜é€ŸåŒ–è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã“ã“ã‚’ç·¨é›†ã—ã¦é€Ÿåº¦ã¨ç²¾åº¦ã‚’èª¿æ•´ï¼‰
# =============================================================================

# ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆé«˜é€ŸåŒ–ã®åŸºç›¤ï¼‰
MODEL_CONFIG = {
    "model_size": "medium",        # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: "tiny"|"base"|"small"|"medium"|"large" (å¤§ãã„ã»ã©ç²¾åº¦â†‘é€Ÿåº¦â†“)
    "device": "cpu",               # ãƒ‡ãƒã‚¤ã‚¹: "cpu"|"cuda" (GPUä½¿ç”¨æ™‚ã¯"cuda")
    "compute_type": "int8",        # è¨ˆç®—ç²¾åº¦: "int8"|"float16"|"float32" (int8ãŒæœ€é€Ÿ)
    "cpu_threads": 8,              # CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°: 1-16 (ç‰©ç†ã‚³ã‚¢æ•°ä»¥å†…ã§å¤šãã™ã‚‹ã»ã©é«˜é€Ÿ)
    "num_workers": 1               # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: 1 (ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æŠ‘ãˆã‚‹ãŸã‚1æ¨å¥¨)
}

# èªè­˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé€Ÿåº¦é‡è¦–ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
TRANSCRIBE_CONFIG = {
    "language": "ja",              # è¨€èªæŒ‡å®šï¼ˆå›ºå®šï¼‰
    "beam_size": 1,                # ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚µã‚¤ã‚º: 1=greedy(æœ€é€Ÿ), 5=é«˜ç²¾åº¦ (1ãŒæœ€é€Ÿ)
    "temperature": 0.0,            # æ¸©åº¦: 0.0=æ±ºå®šè«–çš„(é«˜é€Ÿ), 1.0=å¤šæ§˜æ€§é‡è¦–
    "compression_ratio_threshold": 2.0,  # åœ§ç¸®ç‡é–¾å€¤: 2.4(é«˜ç²¾åº¦)â†’2.0(é«˜é€Ÿ)
    "log_prob_threshold": -0.8,    # ç¢ºç‡é–¾å€¤: -1.0(é«˜ç²¾åº¦)â†’-0.8(é«˜é€Ÿ)
    "no_speech_threshold": 0.4,    # ç„¡éŸ³åˆ¤å®šé–¾å€¤: 0.6(é«˜ç²¾åº¦)â†’0.4(é«˜é€Ÿ)
    "condition_on_previous_text": False,  # å‰ã®ãƒ†ã‚­ã‚¹ãƒˆä¾å­˜: False(é«˜é€Ÿ)
    "initial_prompt": "ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚",  # è¨€èªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    "word_timestamps": False,      # å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: False(é«˜é€Ÿ), True(é«˜ç²¾åº¦)
    "vad_filter": True,           # Voice Activity Detection: True(é«˜é€Ÿ)
    "vad_parameters": {            # VADè©³ç´°è¨­å®š
        "min_silence_duration_ms": 800,  # ç„¡éŸ³åŒºé–“: 500ms(é«˜ç²¾åº¦)â†’800ms(é«˜é€Ÿ)
        "speech_pad_ms": 50,       # éŸ³å£°ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 100msâ†’50ms(é«˜é€Ÿ)
        "threshold": 0.5           # VADé–¾å€¤: 0.5(ç©æ¥µçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°)
    }
}

# éŸ³å£°è¨­å®šï¼ˆå›ºå®šï¼‰
AUDIO_CONFIG = {
    "chunk": 1024,
    "format": pyaudio.paInt16,
    "channels": 1,
    "rate": 16000  # Whisperæ¨å¥¨16kHz
}

# =============================================================================
# ä»¥ä¸‹ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ æœ¬ä½“ï¼ˆé«˜é€ŸåŒ–è¨­å®šã¯ä¸Šéƒ¨ã§å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰
# =============================================================================

def calculate_confidence_metrics(segments, info):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ä¿¡é ¼åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
    try:
        word_confidences = []
        word_count = 0
        total_duration = 0
        
        for segment in segments:
            if hasattr(segment, 'words') and segment.words:
                # å˜èªãƒ¬ãƒ™ãƒ«ã®ä¿¡é ¼åº¦ã‚’å–å¾—
                for word in segment.words:
                    if hasattr(word, 'probability') and word.probability is not None:
                        # å¯¾æ•°ç¢ºç‡ã‚’ä¿¡é ¼åº¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã«å¤‰æ›
                        confidence = min(100.0, max(0.0, (word.probability + 5.0) / 5.0 * 100))
                        word_confidences.append(confidence)
                        word_count += 1
        
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®æƒ…å ±
            if hasattr(segment, 'avg_logprob') and segment.avg_logprob is not None:
                # å¹³å‡å¯¾æ•°ç¢ºç‡ã‚’ä¿¡é ¼åº¦ã«å¤‰æ›
                segment_confidence = min(100.0, max(0.0, (segment.avg_logprob + 5.0) / 5.0 * 100))
                word_confidences.append(segment_confidence)
        
            total_duration += getattr(segment, 'end', 0) - getattr(segment, 'start', 0)
        
        # å…¨ä½“çš„ãªä¿¡é ¼åº¦ã‚’è¨ˆç®—
        if word_confidences:
            overall_confidence = sum(word_confidences) / len(word_confidences)
            min_confidence = min(word_confidences)
            max_confidence = max(word_confidences)
            std_confidence = (sum((x - overall_confidence) ** 2 for x in word_confidences) / len(word_confidences)) ** 0.5
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¨€èªç¢ºç‡ã‚’ä½¿ç”¨
            overall_confidence = info.language_probability * 100 if hasattr(info, 'language_probability') else 50.0
            min_confidence = max_confidence = overall_confidence
            std_confidence = 0.0
            word_count = len(segments)
        
        return {
            'overall_confidence': overall_confidence,
            'min_confidence': min_confidence,
            'max_confidence': max_confidence,
            'std_confidence': std_confidence,
            'word_count': word_count,
            'segment_count': len(segments),
            'audio_duration': getattr(info, 'duration', total_duration),
            'language_probability': getattr(info, 'language_probability', 0.0) * 100,
            'word_confidences': word_confidences
        }
        
    except Exception as e:
        print(f"âš ï¸ ä¿¡é ¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return {
            'overall_confidence': 50.0,
            'min_confidence': 50.0,
            'max_confidence': 50.0,
            'std_confidence': 0.0,
            'word_count': 0,
            'segment_count': len(segments) if segments else 0,
            'audio_duration': 0.0,
            'language_probability': 50.0,
            'word_confidences': []
        }

class AudioRecorder:
    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.frames = []
        self.is_recording = False

    def start_recording(self):
        if self.is_recording:
            print("ã™ã§ã«éŒ²éŸ³ä¸­ã§ã™ã€‚")
            return

        self.frames = []
        self.stream = self.audio.open(
            format=AUDIO_CONFIG["format"],
            channels=AUDIO_CONFIG["channels"],
            rate=AUDIO_CONFIG["rate"],
            input=True,
            frames_per_buffer=AUDIO_CONFIG["chunk"]
        )
        self.is_recording = True
        print("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚'stop' ã¨å…¥åŠ›ã—ã¦çµ‚äº†ã—ã¦ãã ã•ã„ã€‚")
        
        # éŒ²éŸ³é–‹å§‹å¾Œã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç¶™ç¶šå–å¾—
        import threading
        self.recording_thread = threading.Thread(target=self._continuous_recording, daemon=True)
        self.recording_thread.start()

    def _continuous_recording(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éŒ²éŸ³ã‚’ç¶™ç¶šã™ã‚‹"""
        frame_count = 0
        while self.is_recording:
            try:
                data = self.stream.read(AUDIO_CONFIG["chunk"], exception_on_overflow=False)
                self.frames.append(data)
                frame_count += 1
                
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                import numpy as np
                audio_data = np.frombuffer(data, dtype=np.int16)
                if len(audio_data) > 0:
                    volume = np.sqrt(np.mean(audio_data.astype(np.float64)**2))
                    if np.isnan(volume):
                        volume = 0
                else:
                    volume = 0
                    
                if frame_count % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¡¨ç¤º
                    print(f"éŒ²éŸ³ä¸­... ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}, éŸ³é‡: {volume:.0f}")
            except Exception as e:
                print(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
                break
            import time
            time.sleep(0.01)  # 10mså¾…æ©Ÿ

    def stop_recording(self):
        if not self.is_recording:
            print("éŒ²éŸ³ä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None

        self.is_recording = False
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…ã¤
        if hasattr(self, 'recording_thread') and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=1.0)
        
        self.stream.stop_stream()
        self.stream.close()

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            temp_filename = temp_file.name
            wf = wave.open(temp_filename, 'wb')
            wf.setnchannels(AUDIO_CONFIG["channels"])
            wf.setsampwidth(self.audio.get_sample_size(AUDIO_CONFIG["format"]))
            wf.setframerate(AUDIO_CONFIG["rate"])
            wf.writeframes(b''.join(self.frames))
            wf.close()

        print("éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚éŸ³å£°èªè­˜ä¸­...")
        return temp_filename

    def record_chunk(self):
        if self.is_recording:
            try:
                data = self.stream.read(AUDIO_CONFIG["chunk"], exception_on_overflow=False)
                self.frames.append(data)
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                import numpy as np
                audio_data = np.frombuffer(data, dtype=np.int16)
                if len(audio_data) > 0:
                    volume = np.sqrt(np.mean(audio_data.astype(np.float64)**2))
                    if np.isnan(volume):
                        volume = 0
                else:
                    volume = 0
                if len(self.frames) % 10 == 0:  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¡¨ç¤º
                    print(f"éŒ²éŸ³ä¸­... ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(self.frames)}, éŸ³é‡: {volume:.0f}")
            except Exception as e:
                print(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")

    def close(self):
        self.audio.terminate()

def list_audio_devices():
    """åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º"""
    print("\nğŸ¤ åˆ©ç”¨å¯èƒ½ãªéŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹:")
    p = pyaudio.PyAudio()
    for i in range(p.get_device_count()):
        info = p.get_device_info_by_index(i)
        if info['maxInputChannels'] > 0:
            print(f"  {i}: {info['name']} (ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {info['maxInputChannels']}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {info['defaultSampleRate']}Hz)")
    p.terminate()
    print()

def main():
    print("ğŸ¤ Faster Whisper éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ")
    print("ã‚³ãƒãƒ³ãƒ‰: start (éŒ²éŸ³é–‹å§‹), stop (éŒ²éŸ³çµ‚äº†ãƒ»èªè­˜), quit (çµ‚äº†)")
    print("-" * 50)
    
    # éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º
    list_audio_devices()

    # Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆé«˜é€ŸåŒ–è¨­å®šï¼‰
    print("Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = WhisperModel(
        MODEL_CONFIG["model_size"],
        device=MODEL_CONFIG["device"],
        compute_type=MODEL_CONFIG["compute_type"],
        cpu_threads=MODEL_CONFIG["cpu_threads"],
        num_workers=MODEL_CONFIG["num_workers"]
    )
    print("ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    recorder = AudioRecorder()

    try:
        import time
        
        while True:
            command = input("ã‚³ãƒãƒ³ãƒ‰: ").strip().lower()

            if command == "start":
                if not recorder.is_recording:
                    recorder.start_recording()
                    print("éŒ²éŸ³ä¸­ã§ã™... 'stop'ã¨å…¥åŠ›ã—ã¦çµ‚äº†ã—ã¦ãã ã•ã„")
                else:
                    print("ã™ã§ã«éŒ²éŸ³ä¸­ã§ã™ã€‚")
                    
            elif command == "stop":
                if recorder.is_recording:
                    # stopã‚³ãƒãƒ³ãƒ‰å…¥åŠ›æ™‚ã®æ™‚é–“ã‚’è¨˜éŒ²
                    stop_command_time = time.time()
                    
                    temp_file = recorder.stop_recording()
                    if temp_file:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
                        file_size = os.path.getsize(temp_file)
                        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes")
                        
                        if file_size < 1000:  # 1KBæœªæº€ã®å ´åˆã¯è­¦å‘Š
                            print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã¾ã™ã€‚ãƒã‚¤ã‚¯ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        
                        # éŸ³å£°èªè­˜ï¼ˆsync_siriusface.pyã‚’å‚è€ƒã«ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
                        print("éŸ³å£°èªè­˜å‡¦ç†ä¸­...")
                        
                        try:
                            segments, info = model.transcribe(
                                temp_file,
                                language=TRANSCRIBE_CONFIG["language"],
                                beam_size=TRANSCRIBE_CONFIG["beam_size"],
                                temperature=TRANSCRIBE_CONFIG["temperature"],
                                compression_ratio_threshold=TRANSCRIBE_CONFIG["compression_ratio_threshold"],
                                log_prob_threshold=TRANSCRIBE_CONFIG["log_prob_threshold"],
                                no_speech_threshold=TRANSCRIBE_CONFIG["no_speech_threshold"],
                                condition_on_previous_text=TRANSCRIBE_CONFIG["condition_on_previous_text"],
                                initial_prompt=TRANSCRIBE_CONFIG["initial_prompt"],
                                word_timestamps=TRANSCRIBE_CONFIG["word_timestamps"],
                                vad_filter=TRANSCRIBE_CONFIG["vad_filter"],
                                vad_parameters=TRANSCRIBE_CONFIG["vad_parameters"]
                            )
                            
                            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                            segments_list = list(segments)
                            text = "".join(segment.text for segment in segments_list).strip()
                            
                            # stopã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰èªè­˜å®Œäº†ã¾ã§ã®æ™‚é–“ã‚’è¨ˆç®—
                            recognition_end = time.time()
                            total_time_from_stop = recognition_end - stop_command_time
                            
                            # ç°¡æ½”ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰
                            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments_list)}")
                            
                            # ä¿¡é ¼åº¦æƒ…å ±ã‚’è¨ˆç®—ï¼ˆç°¡ç•¥åŒ–ï¼‰
                            confidence_info = calculate_confidence_metrics(segments_list, info)
                            
                            print(f"èªè­˜çµæœ: {text}")
                            print(f"è¨€èª: {info.language} (ç¢ºä¿¡åº¦: {info.language_probability:.2f})")
                            print(f"éŸ³å£°æ™‚é–“: {info.duration:.2f}ç§’")
                            print(f"èªè­˜ç²¾åº¦: {confidence_info['overall_confidence']:.1f}% (å˜èªæ•°: {confidence_info['word_count']})")
                            print(f"â±ï¸  stopã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰å®Œäº†ã¾ã§: {total_time_from_stop:.2f}ç§’")
                            
                            # å‡¦ç†åŠ¹ç‡ã®è¨ˆç®—
                            if info.duration > 0:
                                processing_ratio = total_time_from_stop / info.duration
                                if processing_ratio < 1.0:
                                    print(f"âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿‚æ•°: {processing_ratio:.2f}x (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ˆã‚Š {1/processing_ratio:.1f}å€é«˜é€Ÿ)")
                                else:
                                    print(f"ğŸŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿‚æ•°: {processing_ratio:.2f}x (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ˆã‚Š {processing_ratio:.1f}å€ä½é€Ÿ)")
                            
                        except Exception as transcribe_error:
                            print(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {transcribe_error}")
                        
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                        try:
                            os.unlink(temp_file)
                        except:
                            pass
                    print("-" * 50)
                else:
                    print("éŒ²éŸ³ä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    
            elif command == "quit":
                if recorder.is_recording:
                    recorder.stop_recording()
                print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            else:
                print("ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚start, stop, quit ã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    except KeyboardInterrupt:
        print("\nãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    finally:
        recorder.close()

if __name__ == "__main__":
    main()