#!/usr/bin/env python3
"""
LM Studio ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‹ã‚‰å…¥åŠ›ã—ã¦AIå¿œç­”ã‚’è¡¨ç¤º
"""

import requests
import json
import time

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
MODELS = {
    "1": {"name": "mistralai/magistral-small-2509", "description": "Mistral Smallãƒ¢ãƒ‡ãƒ«"},
    "2": {"name": "openai/gpt-oss-20b", "description": "OpenAI GPT OSS 20Bãƒ¢ãƒ‡ãƒ«"}
}

def select_model():
    """èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
    print("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
    for key, model in MODELS.items():
        print(f"{key}: {model['description']} ({model['name']})")
    
    while True:
        choice = input("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ (1 ã¾ãŸã¯ 2): ").strip()
        if choice in MODELS:
            selected_model = MODELS[choice]["name"]
            print(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {MODELS[choice]['description']}")
            return selected_model
        else:
            print("ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚1 ã¾ãŸã¯ 2 ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

def chat_with_ai(user_message, model):
    """LM Studio APIã§AIã¨ãƒãƒ£ãƒƒãƒˆ"""
    url = "http://localhost:1234/v1/chat/completions"

    payload = {
        "model": model,
        "messages": [
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§æ—¥æœ¬èªå¿œç­”ã‚’æŒ‡å®š
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
            },
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§å…¥åŠ›ã‚’æ¸¡ã™
            {
                "role": "user", 
                "content": user_message
            } 
        ],
        "temperature": 0.7,
        "max_tokens": -1,
        "stream": False
    }

    # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
    try:
        start_time = time.time()  # é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
        response = requests.post(url, json=payload) # POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹

        result = response.json() # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’JSONã¨ã—ã¦è§£æ
        end_time = time.time()  # çµ‚äº†æ™‚é–“ã‚’è¨˜éŒ²
        elapsed_time = end_time - start_time  # çµŒéæ™‚é–“ã‚’è¨ˆç®—

        ai_message = result["choices"][0]["message"]["content"] # AIã®å¿œç­”ã‚’å–å¾—

        return ai_message, elapsed_time  # å¿œç­”ã¨æ™‚é–“ã‚’è¿”ã™

    except requests.exceptions.RequestException as e:
        return f"ã‚¨ãƒ©ãƒ¼: {e}", 0.0

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ¤– LM Studio ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ")
    print("çµ‚äº†ã™ã‚‹ã«ã¯ 'quit' ã¾ãŸã¯ 'exit' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„")
    print("-" * 50)
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    selected_model = select_model()
    
    try:
        while True:
            user_input = input("ã‚ãªãŸ: ").strip()

            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break

            if not user_input:
                continue

            print("AI: ", end="", flush=True)
            ai_response, elapsed_time = chat_with_ai(user_input, selected_model)
            print(ai_response)
            print(f"å¿œç­”æ™‚é–“: {elapsed_time:.2f}ç§’")
            print("-" * 50)
    except KeyboardInterrupt:
        print("\nãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")

if __name__ == "__main__":
    main()